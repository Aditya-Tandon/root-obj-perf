{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7a2b2f5e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initial exploratory code to read ROOT data\n",
    "# optimized code follows in later cells\n",
    "\n",
    "import numpy as np\n",
    "import uproot\n",
    "import awkward as ak\n",
    "\n",
    "root_folder = \"/home/hep/at3722/root-obj-perf/data/hhbbbb\"\n",
    "file_name = \"data_0.root\"\n",
    "file_path = f\"{root_folder}/{file_name}\"\n",
    "print(file_path)\n",
    "\n",
    "tree = uproot.concatenate(file_path + \":Events\", library=\"ak\", max_num_elements=5000)\n",
    "branches = tree\n",
    "\n",
    "# print(tree.keys())\n",
    "idx = 0\n",
    "branches[\"GenPart_pdgId\"][idx], branches[\"GenPart_genPartIdxMother\"][idx]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b84cc15e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def find_mother(particle_idx, all_mothers, particle_ids, target_ids, particles_seen=[]):\n",
    "    mother_idx = all_mothers[particle_idx]\n",
    "    while mother_idx != -1:\n",
    "        mother_id = particle_ids[mother_idx]\n",
    "        if mother_id in target_ids:\n",
    "            return mother_idx\n",
    "        mother_idx = all_mothers[mother_idx]\n",
    "        print(mother_idx)\n",
    "    return -1\n",
    "\n",
    "\n",
    "def find_mother_recursive(particle_idx, all_mothers, particle_ids, target_ids, particles_seen=[]):\n",
    "    mother_idx = all_mothers[particle_idx]\n",
    "    if mother_idx == -1:\n",
    "        return -1\n",
    "    mother_id = particle_ids[mother_idx]\n",
    "    if mother_id in target_ids and mother_id != particle_ids[particle_idx]:\n",
    "        return mother_idx\n",
    "    if mother_idx in particles_seen:\n",
    "        return -1\n",
    "    if mother_id not in target_ids:\n",
    "        return mother_idx\n",
    "    particles_seen.append(mother_idx)\n",
    "    # print(particles_seen)\n",
    "    return find_mother_recursive(mother_idx, all_mothers, particle_ids, target_ids, particles_seen)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3c763d34",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Loop over all events and find b quarks from Higgs or Tau mothers\n",
    "\n",
    "# target_ids = {25, 15} # Higgs and Tau mothers\n",
    "target_ids = {25} # Higgs mothers only\n",
    "\n",
    "all_b_quarks = []\n",
    "for single_event in branches:\n",
    "    particle_ids = single_event[\"GenPart_pdgId\"]\n",
    "    all_mothers = single_event[\"GenPart_genPartIdxMother\"]\n",
    "\n",
    "    b_idxs = ak.where(abs(particle_ids) == 5)[0] # for b quarks\n",
    "    b_idxs_loop = []\n",
    "    b_mom_idxs = []\n",
    "\n",
    "    particles_seen = []\n",
    "    # for i, pid in enumerate(single_event[\"GenPart_pdgId\"]): # update this to just loop over b quark indices\n",
    "    for i in b_idxs:\n",
    "        pid = particle_ids[i]\n",
    "        if abs(pid) == 5: # for b quarks\n",
    "            mom_idx = find_mother_recursive(i, all_mothers, particle_ids, target_ids, particles_seen=particles_seen)\n",
    "            mom_pid = particle_ids[mom_idx]\n",
    "            # print(f\"Checking b idx: {i}, b pid: {pid}, mom idx: {mom_idx}, mom pid: {mom_pid}, particles seen: {particles_seen}\")\n",
    "            if mom_idx != -1 and mom_pid in target_ids:\n",
    "                b_idxs_loop.append(i)\n",
    "                b_mom_idxs.append(mom_idx)\n",
    "                particles_seen.append(i)\n",
    "\n",
    "\n",
    "    # print(\"\\nB hadron indices (ak.where):\", b_idxs)\n",
    "    # print(\"B hadron indices (loop):\", b_idxs_loop)\n",
    "    # print(\"B hadron mother indices (loop):\", b_mom_idxs)\n",
    "\n",
    "    # print(\"Particles seen during search:\", particles_seen)\n",
    "\n",
    "    all_b_quarks.append(ak.Array([b_idxs_loop, b_mom_idxs]))\n",
    "\n",
    "\n",
    "all_b_quarks = ak.Array(all_b_quarks)\n",
    "all_b_quarks[0:2, :, :]  # first two events, particle_idx/mom_idx <-> 0/1, b quark num\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9527bcc8",
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import defaultdict\n",
    "single_event = branches[0]\n",
    "\n",
    "higgs_id = 25\n",
    "all_higgs_decays = defaultdict(list)\n",
    "\n",
    "for event_idx, single_event in enumerate(branches):\n",
    "    particle_ids = single_event[\"GenPart_pdgId\"]\n",
    "    all_mothers = single_event[\"GenPart_genPartIdxMother\"]\n",
    "    higgs_idxs = ak.where(abs(particle_ids) == higgs_id)[0]\n",
    "\n",
    "    higgs_is_mom = defaultdict(list)\n",
    "\n",
    "    for i, pid in enumerate(particle_ids):\n",
    "        mom_idx = find_mother_recursive(i, all_mothers, particle_ids, {higgs_id}, particles_seen=[])\n",
    "        mom_pid = particle_ids[mom_idx]\n",
    "        if mom_idx != -1 and abs(mom_pid) == higgs_id:\n",
    "            # print(f\"Particle idx: {i}, pid: {pid}, mom idx: {mom_idx}, mom pid: {mom_pid}\")\n",
    "            higgs_is_mom[mom_idx].append(i)\n",
    "\n",
    "    all_higgs_decays[event_idx] = higgs_is_mom"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d6c0533b",
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import defaultdict\n",
    "single_event = branches[0]\n",
    "\n",
    "tau_id = 15\n",
    "all_tau_decays = defaultdict(list)\n",
    "\n",
    "for event_idx, single_event in enumerate(branches):\n",
    "    particle_ids = single_event[\"GenPart_pdgId\"]\n",
    "    all_mothers = single_event[\"GenPart_genPartIdxMother\"]\n",
    "    tau_idxs = ak.where(abs(particle_ids) == tau_id)[0]\n",
    "\n",
    "    tau_is_mom = defaultdict(list)\n",
    "\n",
    "    for i, pid in enumerate(particle_ids):\n",
    "        mom_idx = find_mother_recursive(i, all_mothers, particle_ids, {tau_id}, particles_seen=[])\n",
    "        mom_pid = particle_ids[mom_idx]\n",
    "        if mom_idx != -1 and abs(mom_pid) == tau_id:\n",
    "            # print(f\"Particle idx: {i}, pid: {pid}, mom idx: {mom_idx}, mom pid: {mom_pid}\")\n",
    "            tau_is_mom[mom_idx].append(i)\n",
    "\n",
    "    all_tau_decays[event_idx] = tau_is_mom\n",
    "\n",
    "# all_tau_decays"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "54b9c803",
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import defaultdict\n",
    "single_event = branches[0]\n",
    "\n",
    "tau_id = 15\n",
    "\n",
    "\n",
    "particle_ids = single_event[\"GenPart_pdgId\"]\n",
    "all_mothers = single_event[\"GenPart_genPartIdxMother\"]\n",
    "tau_idxs = ak.where(abs(particle_ids) == tau_id)[0]\n",
    "\n",
    "tau_is_mom = defaultdict(list)\n",
    "\n",
    "for i, pid in enumerate(particle_ids):\n",
    "    mom_idx = find_mother_recursive(i, all_mothers, particle_ids, {tau_id}, particles_seen=[])\n",
    "    mom_pid = particle_ids[mom_idx]\n",
    "    if mom_idx != -1 and abs(mom_pid) == tau_id:\n",
    "        # print(f\"Particle idx: {i}, pid: {pid}, mom idx: {mom_idx}, mom pid: {mom_pid}\")\n",
    "        tau_is_mom[mom_idx].append(i)\n",
    "\n",
    "\n",
    "\n",
    "print(\"Tau decay products:\")\n",
    "for mom_idx, decay_products in tau_is_mom.items():\n",
    "    print(f\"  Mother idx: {mom_idx}, Decay products: {particle_ids[decay_products]}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c07948df",
   "metadata": {},
   "source": [
    "## Working code here"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4149cb13",
   "metadata": {},
   "outputs": [],
   "source": [
    "# import json\n",
    "\n",
    "# CONFIG = {\n",
    "#     # \"file_path\": \"/home/hep/at3722/root-obj-perf/data/hhbbbb/data_0.root\",\n",
    "#     \"file_pattern\": \"/home/hep/at3722/root-obj-perf/data/hhbbbb/data_*.root\",\n",
    "#     \"tree_name\": \"Events\",\n",
    "#     \"max_events\": 5000,  # Set to None to run on all events\n",
    "#     \"matching_cone_size\": 0.4,\n",
    "    \n",
    "#     # Define the two collections you want to compare\n",
    "#     \"offline\": {\n",
    "#         \"collection_name\": \"Jet\",\n",
    "#         \"tagger_name\": \"btagPNetB\",\n",
    "#         \"b_tag_cut\": 0.7,\n",
    "#         \"charm_veto_cut\": 0.3,\n",
    "#         \"electron_veto_cut\": 0.2,\n",
    "#         \"muon_veto_cut\": 0.2,\n",
    "#         \"pt_cut\": 20.0,\n",
    "#         \"eta_cut\": 2.4\n",
    "#     },\n",
    "#     \"l1\": {\n",
    "#         \"collection_name\": \"L1puppiJetSC4NG\",\n",
    "#         \"tagger_name\": \"bTagScore\",\n",
    "#         \"b_tag_cut\": 0.7,\n",
    "#         \"charm_veto_cut\": 0.3,\n",
    "#         \"electron_veto_cut\": 0.2,\n",
    "#         \"muon_veto_cut\": 0.2,\n",
    "#         \"pt_cut\": 20.0,\n",
    "#         \"eta_cut\": 2.4\n",
    "#     }\n",
    "# }\n",
    "\n",
    "# with open(\"hh-bbbb-obj-config.json\", \"w\") as config_file:\n",
    "#     json.dump(CONFIG, config_file, indent=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aa966abf",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import uproot\n",
    "import awkward as ak\n",
    "import vector\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.colors as colors\n",
    "from sklearn.metrics import auc\n",
    "import warnings\n",
    "\n",
    "# plotting params\n",
    "plt.rcParams.update({\n",
    "    'figure.figsize': (10, 6),\n",
    "    'axes.grid': True,\n",
    "    'grid.alpha': 0.6,\n",
    "    'grid.linestyle': '--',\n",
    "    'font.size': 14,\n",
    "    \"figure.dpi\": 200,\n",
    "})\n",
    "\n",
    "# Suppress a harmless warning from the vector library with awkward arrays\n",
    "warnings.filterwarnings(\"ignore\", message=\"Passing an awkward array to a ufunc\")\n",
    "\n",
    "# Register the vector library with awkward array\n",
    "ak.behavior.update(vector.backends.awkward.behavior)\n",
    "\n",
    "# --- 1. CONFIGURATION ---\n",
    "# All user-changable settings are here.\n",
    "with open(\"hh-bbbb-obj-config.json\", \"r\") as config_file:\n",
    "    CONFIG = json.load(config_file)\n",
    "\n",
    "# --- 2. DATA LOADING & PREPARATION FUNCTIONS ---\n",
    "\n",
    "def load_and_prepare_data(file_pattern, tree_name, collections_to_load, max_events):\n",
    "    \"\"\"\n",
    "    Loads the ROOT file, restructures the flat branches into objects,\n",
    "    and creates 4-vector representations.\n",
    "    \"\"\"\n",
    "    print(f\"Loading data from {file_pattern}...\")\n",
    "\n",
    "    try:\n",
    "        events = uproot.concatenate(\n",
    "                f\"{file_pattern}:{tree_name}\", \n",
    "                library=\"ak\",\n",
    "                entry_stop=max_events \n",
    "            )\n",
    "    except FileNotFoundError:\n",
    "            print(f\"Error: No files found matching '{file_pattern}'. Please update the path.\")\n",
    "            exit()\n",
    "\n",
    "    print(\"Reshaping data into nested objects...\")\n",
    "    for prefix in collections_to_load:\n",
    "        prefixed_fields = [field for field in events.fields if field.startswith(prefix + \"_\")]\n",
    "        if not prefixed_fields:\n",
    "            print(f\"Warning: No fields found with prefix '{prefix}_'. Skipping.\")\n",
    "            continue\n",
    "        field_map = {field.replace(prefix + \"_\", \"\"): events[field] for field in prefixed_fields}\n",
    "        events[prefix] = ak.zip(field_map)\n",
    "\n",
    "    print(\"Creating 4-vector objects...\")\n",
    "    for prefix in collections_to_load:\n",
    "        if prefix in events.fields and \"pt\" in events[prefix].fields:\n",
    "            \n",
    "            # Default to using the raw pt\n",
    "            pt_field = events[prefix].pt\n",
    "\n",
    "            # Handle mass:\n",
    "            if \"mass\" in events[prefix].fields:\n",
    "                mass_field = events[prefix].mass\n",
    "            elif \"et\" in events[prefix].fields:\n",
    "                # Calculate L1 mass from et, pt, and eta\n",
    "                m2 = (events[prefix].et**2 - events[prefix].pt**2) * (np.cosh(events[prefix].eta)**2)\n",
    "                m2_positive = ak.where(m2 < 0, 0, m2)\n",
    "                mass_field = np.sqrt(m2_positive)\n",
    "            else:\n",
    "                mass_field = ak.zeros_like(pt_field)\n",
    "\n",
    "            # Apply pT Corrections if this is the offline jet\n",
    "            if prefix == CONFIG[\"offline\"][\"collection_name\"]:\n",
    "                print(f\"Applying pT regression corrections to {prefix}...\")\n",
    "                pt_corrected = (\n",
    "                    events[prefix].pt \n",
    "                    * events[prefix].PNetRegPtRawCorr \n",
    "                    * events[prefix].PNetRegPtRawCorrNeutrino\n",
    "                )\n",
    "                # Scale mass by the same correction factor\n",
    "                correction_factor = ak.where(events[prefix].pt > 0, pt_corrected / events[prefix].pt, 1.0)\n",
    "                mass_field = mass_field * correction_factor\n",
    "                pt_field = pt_corrected\n",
    "\n",
    "            elif prefix == CONFIG[\"l1\"][\"collection_name\"] and \"ptCorrection\" in events[prefix].fields:\n",
    "                pt_corrected = events[prefix].pt * events[prefix].ptCorrection\n",
    "                correction_factor = ak.where(events[prefix].pt > 0, pt_corrected / events[prefix].pt, 1.0)\n",
    "                mass_field = mass_field * correction_factor\n",
    "                pt_field = pt_corrected\n",
    "\n",
    "            events[prefix, \"vector\"] = ak.zip(\n",
    "                { \"pt\": pt_field, \"eta\": events[prefix].eta, \"phi\": events[prefix].phi, \"mass\": mass_field, },\n",
    "                with_name=\"Momentum4D\",\n",
    "            )\n",
    "            et_field = np.sqrt(pt_field**2 + mass_field**2) * np.cosh(events[prefix].eta)\n",
    "            events[prefix, \"et\"] = et_field\n",
    "            \n",
    "    print(f\"Loaded and restructured {len(events)} events.\")\n",
    "    return events\n",
    "\n",
    "def select_gen_b_quarks_from_higgs(events):\n",
    "    \"\"\"\n",
    "    Finds all b-quarks that are direct descendants of a Higgs boson.\n",
    "    \"\"\"\n",
    "    print(\"Selecting gen-level b-quarks...\")\n",
    "    is_higgs = events.GenPart.pdgId == 25\n",
    "    higgs_indices = ak.local_index(events.GenPart)[is_higgs]\n",
    "\n",
    "    is_b = abs(events.GenPart.pdgId) == 5\n",
    "    b_mother_idx = events.GenPart.genPartIdxMother\n",
    "    \n",
    "    b_mother_idx_expanded = b_mother_idx[:, :, None]\n",
    "    higgs_indices_expanded = higgs_indices[:, None, :]\n",
    "    \n",
    "    comparison_b = (b_mother_idx_expanded == higgs_indices_expanded)\n",
    "    has_higgs_mother_b = ak.any(comparison_b, axis=2)\n",
    "    \n",
    "    is_b_from_H = is_b & has_higgs_mother_b\n",
    "    gen_b_quarks_from_H = events.GenPart[is_b_from_H]\n",
    "\n",
    "    print(f\"Found {ak.sum(ak.num(gen_b_quarks_from_H))} b-quarks from Higgs decays.\")\n",
    "    return gen_b_quarks_from_H\n",
    "\n",
    "# --- 3. ANALYSIS FUNCTIONS ---\n",
    "\n",
    "def get_efficiency_mask(gen_particles, reco_objects):\n",
    "    \"\"\"Returns a boolean mask for gen_particles, True if matched.\"\"\"\n",
    "    gen_expanded = gen_particles.vector[:, :, None]\n",
    "    reco_expanded = reco_objects.vector[:, None, :]\n",
    "    delta_r_matrix = gen_expanded.deltaR(reco_expanded)\n",
    "    min_delta_r = ak.min(delta_r_matrix, axis=2)\n",
    "    is_matched = min_delta_r < CONFIG[\"matching_cone_size\"]\n",
    "    return ak.fill_none(is_matched, False)\n",
    "\n",
    "def get_purity_mask(gen_particles, reco_objects):\n",
    "    \"\"\"Returns a boolean mask for reco_objects, True if matched.\"\"\"\n",
    "    gen_expanded = gen_particles.vector[:, None, :]\n",
    "    reco_expanded = reco_objects.vector[:, :, None]\n",
    "    delta_r_matrix = reco_expanded.deltaR(gen_expanded)\n",
    "    min_delta_r = ak.min(delta_r_matrix, axis=2)\n",
    "    is_matched = min_delta_r < CONFIG[\"matching_cone_size\"]\n",
    "    return ak.fill_none(is_matched, False)\n",
    "\n",
    "def calculate_roc_points(reco_jets, is_pure_mask, tagger_name):\n",
    "    \"\"\"\n",
    "    Calculates efficiency and mistag points for a ROC curve.\n",
    "    Returns (mistag_points, efficiency_points, auc_score).\n",
    "    \"\"\"\n",
    "    thresholds = np.linspace(0, 1, 101)\n",
    "    eff_points, mistag_points = [], []\n",
    "\n",
    "    signal_jets = reco_jets[is_pure_mask]\n",
    "    mistag_jets = reco_jets[~is_pure_mask]\n",
    "\n",
    "    n_total_signal = ak.sum(ak.num(signal_jets))\n",
    "    n_total_mistag = ak.sum(ak.num(mistag_jets))\n",
    "\n",
    "    for cut in thresholds:\n",
    "        # Calculate Signal Efficiency\n",
    "        n_signal_passing = ak.sum(getattr(signal_jets, tagger_name) > cut)\n",
    "        eff = n_signal_passing / n_total_signal if n_total_signal > 0 else 0\n",
    "        \n",
    "        # Calculate Mistag Rate\n",
    "        n_mistag_passing = ak.sum(getattr(mistag_jets, tagger_name) > cut)\n",
    "        mistag_rate = n_mistag_passing / n_total_mistag if n_total_mistag > 0 else 0\n",
    "        \n",
    "        eff_points.append(eff)\n",
    "        mistag_points.append(mistag_rate)\n",
    "\n",
    "    auc_score = auc(mistag_points, eff_points)\n",
    "    return mistag_points, eff_points, auc_score\n",
    "\n",
    "\n",
    "# --- 4. PLOTTING FUNCTIONS ---\n",
    "\n",
    "def plot_kinematic_comparison(bins, variable, xlabel, title,\n",
    "                              gen_particles, \n",
    "                              offline_objects, offline_mask,\n",
    "                              l1_objects, l1_mask,\n",
    "                              is_purity_plot=False, \n",
    "                              fmt=None, new_fig=True,\n",
    "                              legend_postfix=\"\"):\n",
    "\n",
    "    if new_fig:\n",
    "        plt.figure(figsize=(10, 6))\n",
    "    bin_centers = (bins[:-1] + bins[1:]) / 2\n",
    "    \n",
    "    # Data for Offline Plot\n",
    "    if is_purity_plot:\n",
    "        all_var = ak.to_numpy(ak.flatten(getattr(offline_objects, variable)))\n",
    "        matched_var = ak.to_numpy(ak.flatten(getattr(offline_objects[offline_mask], variable)))\n",
    "    else:\n",
    "        all_var = ak.to_numpy(ak.flatten(getattr(gen_particles, variable)))\n",
    "        matched_var = ak.to_numpy(ak.flatten(getattr(gen_particles[offline_mask], variable)))\n",
    "    \n",
    "    h_total, _ = np.histogram(all_var, bins=bins)\n",
    "    h_matched, _ = np.histogram(matched_var, bins=bins)\n",
    "    \n",
    "    frac_offline = np.divide(h_matched, h_total, out=np.zeros_like(h_total, dtype=float), where=h_total!=0)\n",
    "    # err_offline = np.sqrt(frac_offline * (1 - frac_offline) / np.where(h_total == 0, 1, h_total))\n",
    "    err_offline = np.sqrt(((h_matched + 1) * (h_total - h_matched + 1)) / ((h_total + 2)**2 * (h_total + 3)))  # Ullrich and Xu\n",
    "\n",
    "    plt.errorbar(bin_centers, frac_offline, yerr=err_offline, fmt='o-' if fmt is None else fmt, capsize=5, label='Offline Jet' + legend_postfix)\n",
    "\n",
    "    # Data for L1 Plot\n",
    "    if is_purity_plot:\n",
    "        all_var = ak.to_numpy(ak.flatten(getattr(l1_objects, variable)))\n",
    "        matched_var = ak.to_numpy(ak.flatten(getattr(l1_objects[l1_mask], variable)))\n",
    "    else:\n",
    "        all_var = ak.to_numpy(ak.flatten(getattr(gen_particles, variable)))\n",
    "        matched_var = ak.to_numpy(ak.flatten(getattr(gen_particles[l1_mask], variable)))\n",
    "        \n",
    "    h_total, _ = np.histogram(all_var, bins=bins)\n",
    "    h_matched, _ = np.histogram(matched_var, bins=bins)\n",
    "    \n",
    "    frac_l1 = np.divide(h_matched, h_total, out=np.zeros_like(h_total, dtype=float), where=h_total!=0)\n",
    "    # err_l1 = np.sqrt(frac_l1 * (1 - frac_l1) / np.where(h_total == 0, 1, h_total))\n",
    "    err_l1 = np.sqrt(((h_matched + 1) * (h_total - h_matched + 1)) / ((h_total + 2)**2 * (h_total + 3)))  # Ullrich and Xu\n",
    "\n",
    "    plt.errorbar(bin_centers, frac_l1, yerr=err_l1, fmt='s--' if fmt is None else fmt, capsize=5, label='L1 Jet' + legend_postfix)\n",
    "\n",
    "    # Plot formatting\n",
    "    plt.xlabel(xlabel)\n",
    "    plt.ylabel(\"Efficiency\" if not is_purity_plot else \"Purity\")\n",
    "    plt.title(title)\n",
    "    plt.grid(True, linestyle='--', alpha=0.6)\n",
    "    plt.ylim(0, 1.05)\n",
    "    plt.legend()\n",
    "    plt.show() if new_fig else None\n",
    "\n",
    "def plot_roc_comparison(roc_results):\n",
    "    \"\"\"\n",
    "    Plots multiple ROC curves on the same axes.\n",
    "    roc_results should be a list of tuples:\n",
    "    [(label, (mistag_points, eff_points, auc_score)), ...]\n",
    "    \"\"\"\n",
    "    plt.figure(figsize=(8, 8))\n",
    "    \n",
    "    for label, (mistag_pts, eff_pts, auc_score) in roc_results:\n",
    "        plt.plot( mistag_pts, eff_pts, 'o-', \n",
    "                 label=f'{label} (AUC = {auc_score:.3f})', \n",
    "                 markersize=3)\n",
    "    \n",
    "    plt.ylabel(\"B-Tagging Efficiency\")\n",
    "    plt.xlabel(\"Mistag Rate\")\n",
    "    # plt.yscale('log') \n",
    "    plt.xlim(1e-4, 1.0) \n",
    "    plt.ylim(1e-4, 1.05)\n",
    "    plt.title(\"ROC Curve Comparison: Offline vs. L1 B-Tagging\")\n",
    "    plt.grid(True, linestyle='--', which='both', alpha=0.6)\n",
    "    plt.legend()\n",
    "    plt.show()\n",
    "\n",
    "\n",
    "def plot_btag_map(jets, tagger_name, pt_bins, eta_bins):\n",
    "    \"\"\"\n",
    "    Plots a 2D heatmap of the average b-tag score vs. eta and jet pT.\n",
    "    \"\"\"\n",
    "    print(f\"Plotting 2D b-tag map for {tagger_name}...\")\n",
    "    \n",
    "    # Flatten the jet properties into simple numpy arrays\n",
    "    jet_pt = ak.to_numpy(ak.flatten(jets.vector.pt))\n",
    "    jet_eta = ak.to_numpy(ak.flatten(jets.vector.eta))\n",
    "    jet_btag = ak.to_numpy(ak.flatten(getattr(jets, tagger_name)))\n",
    "\n",
    "    # --- Create the 2D Profile ---\n",
    "    \n",
    "    # 1. Create a 2D histogram of the SUM of b-tag scores in each bin\n",
    "    #    We use the 'weights' argument to sum the b-tag scores\n",
    "    h_sum_btag, xedges, yedges = np.histogram2d(\n",
    "        jet_eta, jet_pt, bins=[eta_bins, pt_bins], weights=jet_btag\n",
    "    )\n",
    "    \n",
    "    # 2. Create a 2D histogram of the COUNT of jets in each bin\n",
    "    h_count_jets, _, _ = np.histogram2d(\n",
    "        jet_eta, jet_pt, bins=[eta_bins, pt_bins]\n",
    "    )\n",
    "    \n",
    "    # 3. Calculate the average score per bin\n",
    "    #    Use np.divide to safely handle division by zero (for empty bins)\n",
    "    h_avg_btag = np.divide(\n",
    "        h_sum_btag, \n",
    "        h_count_jets, \n",
    "        out=np.zeros_like(h_sum_btag), \n",
    "        where=(h_count_jets != 0)\n",
    "    )\n",
    "\n",
    "    # --- Plotting ---\n",
    "    # Use pcolormesh to plot the 2D array. Transpose (T) is needed\n",
    "    # because numpy histogram and pcolormesh have different axis conventions.\n",
    "    im = plt.pcolormesh(\n",
    "        xedges, \n",
    "        yedges, \n",
    "        h_avg_btag.T, \n",
    "        cmap=\"jet\",         # A common colormap for this\n",
    "        norm=colors.Normalize(vmin=0.0, vmax=1.0) # Keep color scale 0-1\n",
    "    )\n",
    "    \n",
    "    plt.ylabel(r\"Corrected Jet $p_T$ [GeV]\")\n",
    "    plt.xlabel(r\"Jet $\\eta$\")\n",
    "    plt.title(f\"Average b-tag score ({tagger_name}) vs. $p_T$ and $\\eta$\")\n",
    "    \n",
    "    # Add a color bar, which represents your z-axis\n",
    "    cbar = plt.colorbar(im)\n",
    "    cbar.set_label(\"Average b-tag score\")\n",
    "    \n",
    "    plt.show()\n",
    "\n",
    "\n",
    "def plot_matching_criteria(gen_particles, reco_objects):\n",
    "    \"\"\"\n",
    "    Plots a 2D heatmap of (reco_pT / gen_pT) vs. dR\n",
    "    for the closest reco_object to each gen_particle.\n",
    "    \"\"\"\n",
    "    print(\"Plotting pT response vs. dR matching criteria...\")\n",
    "    \n",
    "    # 1. Create the all-to-all deltaR matrix\n",
    "    # gen_expanded shape: (events, n_gen, 1)\n",
    "    # reco_expanded shape: (events, 1, n_reco)\n",
    "    gen_expanded = gen_particles.vector[:, :, None]\n",
    "    reco_expanded = reco_objects.vector[:, None, :]\n",
    "    delta_r_matrix = gen_expanded.deltaR(reco_expanded)\n",
    "\n",
    "    # 2. Find the index of the closest reco_object for each gen_particle\n",
    "    #    shape: (events, n_gen)\n",
    "    closest_reco_idx = ak.argmin(delta_r_matrix, axis=2)\n",
    "    \n",
    "    # 3. Get the dR value for this closest match\n",
    "    #    shape: (events, n_gen)\n",
    "    min_delta_r = ak.min(delta_r_matrix, axis=2)\n",
    "\n",
    "    # 4. Get the pT of the gen particles\n",
    "    #    shape: (events, n_gen)\n",
    "    gen_pt = gen_particles.vector.pt\n",
    "    \n",
    "    # 5. Get the pT of all reco jets in each event\n",
    "    #    shape: (events, n_reco)\n",
    "    reco_pt = reco_objects.vector.pt\n",
    "    \n",
    "    # 6. Use the 'closest_reco_idx' to \"pick\" the pT of the matched jet\n",
    "    #    This is the \"fancy indexing\" that matches gen to reco\n",
    "    matched_reco_pt = reco_pt[closest_reco_idx]\n",
    "    \n",
    "    # 7. Calculate the pT ratio (reco / gen)\n",
    "    #    We must use ak.where to prevent division by zero\n",
    "    pt_ratio = ak.where(gen_pt > 0, matched_reco_pt / gen_pt, np.nan)\n",
    "\n",
    "    # 8. Flatten everything into 1D numpy arrays for plotting\n",
    "    flat_delta_r = ak.to_numpy(ak.flatten(min_delta_r))\n",
    "    flat_pt_ratio = ak.to_numpy(ak.flatten(pt_ratio))\n",
    "    \n",
    "    # 9. Remove any invalid 'nan' values\n",
    "    valid_mask = ~np.isnan(flat_pt_ratio)\n",
    "    flat_delta_r = flat_delta_r[valid_mask]\n",
    "    flat_pt_ratio = flat_pt_ratio[valid_mask]\n",
    "\n",
    "    # --- Plotting ---\n",
    "    plt.figure(figsize=(10, 8))\n",
    "    \n",
    "    # We use a 2D histogram (hist2d) to create the heatmap\n",
    "    plt.hist2d(\n",
    "        flat_delta_r, \n",
    "        flat_pt_ratio, \n",
    "        bins=[np.linspace(0, 2, 50), np.linspace(0, 2, 50)], \n",
    "        cmap='viridis', \n",
    "        norm=colors.LogNorm()  # Use a log scale for color to see faint spots\n",
    "    )\n",
    "    \n",
    "    # Draw a red line at dR = 0.4 to show our matching cut\n",
    "    plt.axvline(x=CONFIG[\"matching_cone_size\"], color='red', linestyle='--', label=f'Matching Cut (ΔR={CONFIG[\"matching_cone_size\"]})')\n",
    "    \n",
    "    plt.xlabel(\"ΔR (gen b-quark, closest reco jet)\")\n",
    "    plt.ylabel(r\"p$_T$ Response (reco p$_T$ / gen p$_T$)\")\n",
    "    plt.title(\"p$_T$ Response vs. ΔR for b-quark to Jet Matching\")\n",
    "    plt.legend()\n",
    "    \n",
    "    # Add a color bar\n",
    "    cbar = plt.colorbar()\n",
    "    cbar.set_label(\"Number of Gen b-quarks\")\n",
    "    \n",
    "    plt.show()\n",
    "\n",
    "def plot_before_after_cuts(variable, bins, xlabel, title,\n",
    "                          gen_particles, \n",
    "                          reco_offline, reco_l1,\n",
    "                          is_purity_plot=False):\n",
    "    \"\"\"\n",
    "    Plots efficiency/purity before and after custom cuts.\n",
    "    \"\"\"\n",
    "    # Before Cuts\n",
    "    if is_purity_plot:\n",
    "        offline_mask = get_purity_mask(gen_particles, reco_offline)\n",
    "        l1_mask = get_purity_mask(gen_particles, reco_l1)\n",
    "    else:\n",
    "        offline_mask = get_efficiency_mask(gen_particles, reco_offline)\n",
    "        l1_mask = get_efficiency_mask(gen_particles, reco_l1)\n",
    "    \n",
    "    plot_kinematic_comparison(bins, variable, xlabel, title,\n",
    "                              gen_particles, \n",
    "                              reco_offline, offline_mask,\n",
    "                              reco_l1, l1_mask,\n",
    "                              is_purity_plot=is_purity_plot, fmt='o--',\n",
    "                              new_fig=False,\n",
    "                              legend_postfix=\" (Before Cuts)\"\n",
    "                              )\n",
    "\n",
    "    # After Cuts\n",
    "    reco_offline_cut = apply_custom_offline_cuts(reco_offline, CONFIG)\n",
    "    reco_l1_cut = apply_custom_l1_cuts(reco_l1, CONFIG)\n",
    "    \n",
    "    if is_purity_plot:\n",
    "        offline_mask_cut = get_purity_mask(gen_particles, reco_offline_cut)\n",
    "        l1_mask_cut = get_purity_mask(gen_particles, reco_l1_cut)\n",
    "    else:\n",
    "        offline_mask_cut = get_efficiency_mask(gen_particles, reco_offline_cut)\n",
    "        l1_mask_cut = get_efficiency_mask(gen_particles, reco_l1_cut)\n",
    "    \n",
    "    plot_kinematic_comparison(bins, variable, xlabel, title,\n",
    "                              gen_particles, \n",
    "                              reco_offline_cut, offline_mask_cut,\n",
    "                              reco_l1_cut, l1_mask_cut,\n",
    "                              is_purity_plot=is_purity_plot, fmt='s--', \n",
    "                              new_fig=False,\n",
    "                                legend_postfix=\" (After Cuts)\"\n",
    "                              )\n",
    "    plt.show()\n",
    "\n",
    "\n",
    "# --- 5. SELECTION CUT FUNCTIONS ---\n",
    "def apply_custom_offline_cuts(reco_jets_offline, config):\n",
    "    \n",
    "    # 1. Define your b-tagging cut\n",
    "    b_tag_cut = config[\"offline\"][\"b_tag_cut\"]\n",
    "\n",
    "    # 2. Define your anti-fake cuts\n",
    "    charm_veto_cut = config[\"offline\"][\"charm_veto_cut\"]\n",
    "    electron_veto_cut = config[\"offline\"][\"electron_veto_cut\"]\n",
    "    muon_veto_cut = config[\"offline\"][\"muon_veto_cut\"]\n",
    "    pt_cut = config[\"offline\"][\"pt_cut\"]\n",
    "    eta_cut = config[\"offline\"][\"eta_cut\"]\n",
    "\n",
    "    tagger_name = config[\"offline\"][\"tagger_name\"]\n",
    "\n",
    "    pt_mask = reco_jets_offline.pt > pt_cut\n",
    "    eta_mask = abs(reco_jets_offline.eta) < eta_cut\n",
    "\n",
    "    print(f\"\\nApplying custom pT cut of {pt_cut} GeV...\")\n",
    "    final_offline_mask = pt_mask & eta_mask\n",
    "\n",
    "    # 3. Apply the cuts to the offline jet collection\n",
    "    print(f\"\\nApplying custom cuts for {tagger_name}...\")\n",
    "\n",
    "    if tagger_name.startswith(\"btagPNet\"):\n",
    "        b_jet_mask = (reco_jets_offline.btagPNetB > b_tag_cut)\n",
    "        charm_veto_mask = (reco_jets_offline.btagPNetCvB < charm_veto_cut)\n",
    "        final_offline_mask = final_offline_mask & charm_veto_mask & b_jet_mask\n",
    "\n",
    "    elif tagger_name.startswith(\"btagUParTAK4\"):\n",
    "        b_jet_mask = (reco_jets_offline.btagUParTAK4probb > b_tag_cut)\n",
    "        charm_veto_mask = (reco_jets_offline.btagUParTAK4CvB < charm_veto_cut)\n",
    "        electron_veto_mask = (reco_jets_offline.btagUParTAK4Ele < electron_veto_cut)\n",
    "        muon_veto_mask = (reco_jets_offline.btagUParTAK4Mu < muon_veto_cut)\n",
    "\n",
    "        final_offline_mask = final_offline_mask & charm_veto_mask & electron_veto_mask & muon_veto_mask & b_jet_mask\n",
    "\n",
    "    reco_jets_offline = reco_jets_offline[final_offline_mask]\n",
    "    \n",
    "    return reco_jets_offline\n",
    "\n",
    "def apply_custom_l1_cuts(reco_jets_l1, config):\n",
    "\n",
    "    pt_cut = config[\"l1\"][\"pt_cut\"]\n",
    "    eta_cut = config[\"l1\"][\"eta_cut\"]\n",
    "    b_tag_cut = config[\"l1\"][\"b_tag_cut\"]\n",
    "    reco_jets_l1 = reco_jets_l1[abs(reco_jets_l1.eta) < eta_cut]\n",
    "    reco_jets_l1 = reco_jets_l1[reco_jets_l1.pt > pt_cut]\n",
    "    reco_jets_l1 = reco_jets_l1[getattr(reco_jets_l1, config[\"l1\"][\"tagger_name\"]) > b_tag_cut]\n",
    "    return reco_jets_l1\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c7bce4fd",
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_analysis(CONFIG):\n",
    "    \"\"\"\n",
    "    Main function to run the analysis with custom cuts.\n",
    "    \"\"\"\n",
    "    print(\"Starting analysis with custom cuts...\")\n",
    "\n",
    "    # --- Load and Prepare Data ---\n",
    "    collections = [\n",
    "        \"GenPart\", \n",
    "        CONFIG[\"offline\"][\"collection_name\"], \n",
    "        CONFIG[\"l1\"][\"collection_name\"]\n",
    "    ]\n",
    "    events = load_and_prepare_data(\n",
    "        CONFIG[\"file_pattern\"], \n",
    "        CONFIG[\"tree_name\"], \n",
    "        collections, \n",
    "        CONFIG[\"max_events\"]\n",
    "    )\n",
    "\n",
    "\n",
    "    gen_b_quarks = select_gen_b_quarks_from_higgs(events)\n",
    "\n",
    "    # Fiduciary cuts for gen particles\n",
    "    print(\"\\nApplying fiducial cuts to generated b-quarks...\")\n",
    "\n",
    "    pt_gen_cut = CONFIG[\"gen\"][\"pt_cut\"]\n",
    "    eta_gen_cut = CONFIG[\"gen\"][\"eta_cut\"]\n",
    "\n",
    "    gen_b_quarks = gen_b_quarks[(gen_b_quarks.pt > pt_gen_cut) & (abs(gen_b_quarks.eta) < eta_gen_cut)]\n",
    "\n",
    "    gen_pt = ak.to_numpy(ak.flatten(gen_b_quarks.pt))\n",
    "    gen_eta = ak.to_numpy(ak.flatten(gen_b_quarks.eta))\n",
    "    print(f\"Number of gen-level b-quarks after fiducial cuts: {len(gen_pt)}\")\n",
    "\n",
    "    plt.hist(gen_pt, bins=100, range=(0, 500), alpha=0.5, label=\"Generated $p_T$\")\n",
    "    plt.xlabel(\"Value\")\n",
    "    plt.ylabel(\"Counts\")\n",
    "    plt.title(\"Generated b-quark $p_T$ distribution after fiducial Cuts\")\n",
    "    plt.legend()\n",
    "    plt.show()\n",
    "\n",
    "    plt.hist(gen_eta, bins=100, range=(-3, 3), alpha=0.5, label=\"Generated $\\\\eta$\")\n",
    "    plt.xlabel(\"Value\")\n",
    "    plt.ylabel(\"Counts\")\n",
    "    plt.title(\"Generated b-quark $\\\\eta$ distribution after fiducial Cuts\")\n",
    "    plt.legend()\n",
    "    plt.show()\n",
    "\n",
    "    plt.scatter(gen_eta, gen_pt, alpha=0.2, marker='o', s=2)\n",
    "    plt.xlabel(\"Generated $\\\\eta$\")\n",
    "    plt.ylabel(\"Generated $p_T$\")\n",
    "    plt.title(\"Generated b-quark $p_T$ vs $\\\\eta$ distribution after fiducial Cuts\")\n",
    "    plt.show()\n",
    "\n",
    "    # --- Get Baseline Reconstructed Collections ---\n",
    "    reco_jets_offline = events[CONFIG[\"offline\"][\"collection_name\"]]\n",
    "    reco_jets_l1 = events[CONFIG[\"l1\"][\"collection_name\"]]\n",
    "\n",
    "    print(\"\\nPlotting kinematic distributions before custom cuts...\")\n",
    "    pt_bins = np.linspace(0, 500, 201)\n",
    "    eta_bins = np.linspace(-3, 3, 201)\n",
    "    b_bins = np.linspace(0, 1, 101)\n",
    "\n",
    "    plt.hist(ak.to_numpy(ak.flatten(reco_jets_offline.pt)), bins=pt_bins, alpha=0.5, label=\"Offline Jets\")\n",
    "    plt.hist(ak.to_numpy(ak.flatten(reco_jets_l1.pt)), bins=pt_bins, alpha=0.5, label=\"L1 Jets\")\n",
    "    plt.xlabel(\"Jet $p_T$ [GeV]\")\n",
    "    plt.ylabel(\"Counts\")\n",
    "    plt.title(\"Reconstructed Jet $p_T$ Distribution Before Custom Cuts\")\n",
    "    plt.legend()\n",
    "    plt.show()\n",
    "\n",
    "    plt.hist(ak.to_numpy(ak.flatten(reco_jets_offline.eta)), bins=eta_bins, alpha=0.5, label=\"Offline Jets\")\n",
    "    plt.hist(ak.to_numpy(ak.flatten(reco_jets_l1.eta)), bins=eta_bins, alpha=0.5, label=\"L1 Jets\")\n",
    "    plt.xlabel(\"Jet $\\\\eta$\")\n",
    "    plt.ylabel(\"Counts\")\n",
    "    plt.title(\"Reconstructed Jet $\\\\eta$ Distribution Before Custom Cuts\")\n",
    "    plt.legend()\n",
    "    plt.show()\n",
    "\n",
    "    plt.hist(ak.to_numpy(ak.flatten(getattr(reco_jets_offline, CONFIG[\"offline\"][\"tagger_name\"]))), bins=b_bins, alpha=0.5, label=\"Offline Jets\")\n",
    "    plt.hist(ak.to_numpy(ak.flatten(getattr(reco_jets_l1, CONFIG[\"l1\"][\"tagger_name\"]))), bins=b_bins, alpha=0.5, label=\"L1 Jets\")\n",
    "    plt.xlabel(\"Jet B-Tag Score\")\n",
    "    plt.ylabel(\"Counts\")\n",
    "    plt.title(\"Reconstructed Jet B-Tag Score Distribution Before Custom Cuts\")\n",
    "    plt.legend()\n",
    "    plt.show()\n",
    "\n",
    "    plt.scatter(ak.to_numpy(ak.flatten(reco_jets_offline.eta)), ak.to_numpy(ak.flatten(reco_jets_offline.pt)), alpha=0.1, label=\"Offline Jets\", marker='o', s=5)\n",
    "    plt.scatter(ak.to_numpy(ak.flatten(reco_jets_l1.eta)), ak.to_numpy(ak.flatten(reco_jets_l1.pt)), alpha=0.1, label=\"L1 Jets\", marker='o', s=5)\n",
    "    plt.xlabel(\"Jet $\\\\eta$\")\n",
    "    plt.ylabel(\"Jet $p_T$ [GeV]\")\n",
    "    plt.title(\"Jet $p_T$ vs $\\\\eta$ Distribution Before Custom Cuts\")\n",
    "    plt.legend()\n",
    "    plt.show()\n",
    "\n",
    "\n",
    "    print(\"\\nPlotting b-tag vs jet pT and jet $\\\\eta$ before custom cuts...\")\n",
    "\n",
    "    plot_btag_map(reco_jets_offline, CONFIG[\"offline\"][\"tagger_name\"], pt_bins, eta_bins)\n",
    "    plot_btag_map(reco_jets_l1, CONFIG[\"l1\"][\"tagger_name\"], pt_bins, eta_bins)\n",
    "\n",
    "\n",
    "\n",
    "    print(\"\\nApplying custom cuts for high purity b-jets...\")\n",
    "\n",
    "    reco_jets_offline = apply_custom_offline_cuts(reco_jets_offline, CONFIG)\n",
    "    reco_jets_l1 = apply_custom_l1_cuts(reco_jets_l1, CONFIG)\n",
    "\n",
    "    print(\"\\nPlotting kinematic distributions after custom cuts...\")\n",
    "    plt.hist(ak.to_numpy(ak.flatten(reco_jets_offline.pt)), bins=pt_bins, alpha=0.5, label=\"Offline Jets\")\n",
    "    plt.hist(ak.to_numpy(ak.flatten(reco_jets_l1.pt)), bins=pt_bins, alpha=0.5, label=\"L1 Jets\")\n",
    "    plt.xlabel(\"Jet $p_T$ [GeV]\")\n",
    "    plt.ylabel(\"Counts\")\n",
    "    plt.title(\"Reconstructed Jet $p_T$ Distribution After Custom Cuts\")\n",
    "    plt.legend()\n",
    "    plt.show()\n",
    "\n",
    "    plt.hist(ak.to_numpy(ak.flatten(reco_jets_offline.eta)), bins=eta_bins, alpha=0.5, label=\"Offline Jets\")\n",
    "    plt.hist(ak.to_numpy(ak.flatten(reco_jets_l1.eta)), bins=eta_bins, alpha=0.5, label=\"L1 Jets\")\n",
    "    plt.xlabel(\"Jet $\\\\eta$\")\n",
    "    plt.ylabel(\"Counts\")\n",
    "    plt.title(\"Reconstructed Jet $\\\\eta$ Distribution After Custom Cuts\")\n",
    "    plt.legend()\n",
    "    plt.show()\n",
    "\n",
    "    plt.hist(ak.to_numpy(ak.flatten(getattr(reco_jets_offline, CONFIG[\"offline\"][\"tagger_name\"]))), bins=b_bins, alpha=0.5, label=\"Offline Jets\")\n",
    "    plt.hist(ak.to_numpy(ak.flatten(getattr(reco_jets_l1, CONFIG[\"l1\"][\"tagger_name\"]))), bins=b_bins, alpha=0.5, label=\"L1 Jets\")\n",
    "    plt.xlabel(\"Jet B-Tag Score\")\n",
    "    plt.ylabel(\"Counts\")\n",
    "    plt.title(\"Reconstructed Jet B-Tag Score Distribution After Custom Cuts\")\n",
    "    plt.legend()\n",
    "    plt.show()\n",
    "\n",
    "    plt.scatter(ak.to_numpy(ak.flatten(reco_jets_offline.eta)), ak.to_numpy(ak.flatten(reco_jets_offline.pt)), alpha=0.1, label=\"Offline Jets\", marker='o', s=5)\n",
    "    plt.scatter(ak.to_numpy(ak.flatten(reco_jets_l1.eta)), ak.to_numpy(ak.flatten(reco_jets_l1.pt)), alpha=0.1, label=\"L1 Jets\", marker='o', s=5)\n",
    "    plt.xlabel(\"Jet $\\\\eta$\")\n",
    "    plt.ylabel(\"Jet $p_T$ [GeV]\")\n",
    "    plt.title(\"Jet $p_T$ vs $\\\\eta$ Distribution After Custom Cuts\")\n",
    "    plt.legend()\n",
    "    plt.show()\n",
    "\n",
    "    print(\"\\nPlotting b-tag vs jet pT and jet $\\\\eta$ after custom cuts...\")\n",
    "\n",
    "    plot_btag_map(reco_jets_offline, CONFIG[\"offline\"][\"tagger_name\"], pt_bins, eta_bins)\n",
    "    plot_btag_map(reco_jets_l1, CONFIG[\"l1\"][\"tagger_name\"], pt_bins, eta_bins)\n",
    "\n",
    "    print(\"\\nPlotting matching criteria...\")\n",
    "    plot_matching_criteria(gen_b_quarks, reco_jets_offline)\n",
    "    plot_matching_criteria(gen_b_quarks, reco_jets_l1)\n",
    "\n",
    "    print(\"\\nRunning analysis...\")\n",
    "\n",
    "    # --- Efficiency Analysis ---\n",
    "    b_quarks_is_matched_offline = get_efficiency_mask(gen_b_quarks, reco_jets_offline)\n",
    "    b_quarks_is_matched_l1 = get_efficiency_mask(gen_b_quarks, reco_jets_l1)\n",
    "\n",
    "    print(\"Plotting reconstruction efficiencies...\")\n",
    "    plot_kinematic_comparison(\n",
    "        bins=np.linspace(0, 500, 51), variable=\"pt\",\n",
    "        xlabel=r\"Generated b-quark $p_T$ [GeV]\", title=\"Reco Efficiency vs. $p_T$\",\n",
    "        gen_particles=gen_b_quarks,\n",
    "        offline_objects=reco_jets_offline, offline_mask=b_quarks_is_matched_offline,\n",
    "        l1_objects=reco_jets_l1, l1_mask=b_quarks_is_matched_l1\n",
    "    )\n",
    "\n",
    "    plot_kinematic_comparison(\n",
    "        bins=np.linspace(-3, 3, 61), variable=\"eta\",\n",
    "        xlabel=\"Generated b-quark $\\\\eta$\", title=\"Reco Efficiency vs. $\\\\eta$\",\n",
    "        gen_particles=gen_b_quarks,\n",
    "        offline_objects=reco_jets_offline, offline_mask=b_quarks_is_matched_offline,\n",
    "        l1_objects=reco_jets_l1, l1_mask=b_quarks_is_matched_l1\n",
    "    )\n",
    "\n",
    "    plot_before_after_cuts(\n",
    "        variable=\"pt\", bins=np.linspace(0, 500, 51), xlabel=r\"Generated b-quark $p_T$ [GeV]\", title=\"Reco Efficiency vs. $p_T$\",\n",
    "        gen_particles=gen_b_quarks,\n",
    "        reco_offline=events[CONFIG[\"offline\"][\"collection_name\"]],\n",
    "        reco_l1=events[CONFIG[\"l1\"][\"collection_name\"]],\n",
    "        is_purity_plot=False\n",
    "    )\n",
    "\n",
    "    plot_before_after_cuts(\n",
    "        variable=\"eta\", bins=np.linspace(-3, 3, 61), xlabel=\"Generated b-quark $\\\\eta$\", title=\"Reco Efficiency vs. $\\\\eta$\",\n",
    "        gen_particles=gen_b_quarks,\n",
    "        reco_offline=events[CONFIG[\"offline\"][\"collection_name\"]],\n",
    "        reco_l1=events[CONFIG[\"l1\"][\"collection_name\"]],\n",
    "        is_purity_plot=False\n",
    "    )\n",
    "    \n",
    "\n",
    "    # --- Purity Analysis ---\n",
    "    is_reco_jet_pure_offline = get_purity_mask(gen_b_quarks, reco_jets_offline)\n",
    "    is_reco_jet_pure_l1 = get_purity_mask(gen_b_quarks, reco_jets_l1)\n",
    "\n",
    "    print(\"Plotting purity...\")\n",
    "    plot_kinematic_comparison(\n",
    "        bins=np.linspace(0, 500, 51), variable=\"pt\",\n",
    "        xlabel=\"Reconstructed Jet $p_T$ [GeV]\", title=\"Jet Purity vs. $p_T$\",\n",
    "        gen_particles=gen_b_quarks, # gen_particles is not used for purity plot\n",
    "        offline_objects=reco_jets_offline, offline_mask=is_reco_jet_pure_offline,\n",
    "        l1_objects=reco_jets_l1, l1_mask=is_reco_jet_pure_l1,\n",
    "        is_purity_plot=True\n",
    "    )\n",
    "\n",
    "    plot_kinematic_comparison(\n",
    "        bins=np.linspace(-3, 3, 51), variable=\"eta\",\n",
    "        xlabel=\"Reconstructed Jet $\\\\eta$\", title=\"Jet Purity vs. $\\\\eta$\",\n",
    "        gen_particles=gen_b_quarks, # gen_particles is not used for purity plot\n",
    "        offline_objects=reco_jets_offline, offline_mask=is_reco_jet_pure_offline,\n",
    "        l1_objects=reco_jets_l1, l1_mask=is_reco_jet_pure_l1,\n",
    "        is_purity_plot=True\n",
    "    )\n",
    "\n",
    "    plot_before_after_cuts(\n",
    "        variable=\"pt\", bins=np.linspace(0, 500, 51), xlabel=\"Reconstructed Jet $p_T$ [GeV]\", title=\"Jet Purity vs. $p_T$\",\n",
    "        gen_particles=gen_b_quarks,\n",
    "        reco_offline=events[CONFIG[\"offline\"][\"collection_name\"]],\n",
    "        reco_l1=events[CONFIG[\"l1\"][\"collection_name\"]],\n",
    "        is_purity_plot=True\n",
    "    )\n",
    "    \n",
    "\n",
    "    plot_before_after_cuts(\n",
    "        variable=\"eta\", bins=np.linspace(-3, 3, 61), xlabel=\"Reconstructed Jet $\\\\eta$\", title=\"Jet Purity vs. $\\\\eta$\",\n",
    "        gen_particles=gen_b_quarks,\n",
    "        reco_offline=events[CONFIG[\"offline\"][\"collection_name\"]],\n",
    "        reco_l1=events[CONFIG[\"l1\"][\"collection_name\"]],\n",
    "        is_purity_plot=True\n",
    "    )\n",
    "\n",
    "\n",
    "\n",
    "    # --- ROC Curve Analysis ---\n",
    "    print(\"Calculating ROC curves...\")\n",
    "\n",
    "    roc_offline = calculate_roc_points(\n",
    "        reco_jets_offline, \n",
    "        is_reco_jet_pure_offline, \n",
    "        CONFIG[\"offline\"][\"tagger_name\"]\n",
    "    )\n",
    "\n",
    "    roc_l1 = calculate_roc_points(\n",
    "        reco_jets_l1, \n",
    "        is_reco_jet_pure_l1, \n",
    "        CONFIG[\"l1\"][\"tagger_name\"]\n",
    "    )\n",
    "\n",
    "    plot_roc_comparison([\n",
    "        (\"Offline\", roc_offline),\n",
    "        (\"L1\", roc_l1)\n",
    "    ])\n",
    "\n",
    "    print(\"\\nAnalysis Complete!\")\n",
    "    return events\n",
    "\n",
    "\n",
    "\n",
    "with open(\"hh-bbbb-obj-config.json\", \"r\") as config_file:\n",
    "    CONFIG = json.load(config_file)\n",
    "\n",
    "events = run_analysis(CONFIG)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f65a6079",
   "metadata": {},
   "outputs": [],
   "source": [
    "def gen_b_masks(events):\n",
    "    \"\"\"\n",
    "    For each event, checks if at least n b-jets are found within the top k jets.\n",
    "    Returns a boolean mask per event.\n",
    "    \"\"\"\n",
    "\n",
    "    gen_b_from_higgs = select_gen_b_quarks_from_higgs(events)\n",
    "\n",
    "    pt_cut_gen = CONFIG[\"gen\"][\"pt_cut\"]\n",
    "    eta_cut_gen = CONFIG[\"gen\"][\"eta_cut\"]\n",
    "\n",
    "    gen_b_from_higgs = gen_b_from_higgs[(gen_b_from_higgs.pt > pt_cut_gen) & (abs(gen_b_from_higgs.eta) < eta_cut_gen)]\n",
    "\n",
    "    base_jets_offline = events[CONFIG[\"offline\"][\"collection_name\"]]\n",
    "    base_l1_jets = events[CONFIG[\"l1\"][\"collection_name\"]]\n",
    "\n",
    "    pt_ordered_offline = base_jets_offline[ak.argsort(base_jets_offline.vector.pt, ascending=False)]\n",
    "    pt_ordered_l1 = base_l1_jets[ak.argsort(base_l1_jets.vector.pt, ascending=False)]\n",
    "\n",
    "    b_score_ordered_offline = base_jets_offline[ak.argsort(getattr(base_jets_offline, CONFIG[\"offline\"][\"tagger_name\"]), ascending=False)]\n",
    "    b_score_ordered_l1 = base_l1_jets[ak.argsort(getattr(base_l1_jets, CONFIG[\"l1\"][\"tagger_name\"]), ascending=False)]\n",
    "\n",
    "    true_pt_offline_mask = get_purity_mask(gen_b_from_higgs, pt_ordered_offline)\n",
    "    true_pt_l1_mask = get_purity_mask(gen_b_from_higgs, pt_ordered_l1)\n",
    "\n",
    "    true_btag_offline_mask = get_purity_mask(gen_b_from_higgs, b_score_ordered_offline)\n",
    "    true_btag_l1_mask = get_purity_mask(gen_b_from_higgs, b_score_ordered_l1)\n",
    "\n",
    "    pt_ordered_offline = pt_ordered_offline[true_pt_offline_mask]\n",
    "    pt_ordered_l1 = pt_ordered_l1[true_pt_l1_mask]\n",
    "\n",
    "    b_score_ordered_offline = b_score_ordered_offline[true_btag_offline_mask]\n",
    "    b_score_ordered_l1 = b_score_ordered_l1[true_btag_l1_mask]\n",
    "\n",
    "    return {\"gen_b_from_higgs\": gen_b_from_higgs,\n",
    "            \"ordered\": (pt_ordered_offline, pt_ordered_l1, b_score_ordered_offline, b_score_ordered_l1), \n",
    "            \"masks\": (true_pt_offline_mask, true_pt_l1_mask, true_btag_offline_mask, true_btag_l1_mask)\n",
    "            }\n",
    "\n",
    "def find_n_jets_rolling(gen_b_from_higgs, ordered, masks, n, k):\n",
    "    top_k_pt_offline = ordered[0][:, :k]\n",
    "    top_k_pt_l1 = ordered[1][:, :k]\n",
    "\n",
    "    top_k_btag_offline = ordered[2][:, :k]\n",
    "    top_k_btag_l1 = ordered[3][:, :k]\n",
    "\n",
    "    eff_pt_offline = ak.sum(ak.num(top_k_pt_offline)) / ak.sum(ak.num(gen_b_from_higgs))\n",
    "    eff_pt_l1 = ak.sum(ak.num(top_k_pt_l1)) / ak.sum(ak.num(gen_b_from_higgs))\n",
    "\n",
    "    eff_btag_offline = ak.sum(ak.num(top_k_btag_offline)) / ak.sum(ak.num(gen_b_from_higgs))\n",
    "    eff_btag_l1 = ak.sum(ak.num(top_k_btag_l1)) / ak.sum(ak.num(gen_b_from_higgs))\n",
    "\n",
    "    true_pt_offline_mask = masks[0][:, :k]\n",
    "    more_than_n_mask_offline = ak.sum(true_pt_offline_mask, axis=1) >= n\n",
    "    more_than_n_efficiency_offline = ak.sum(more_than_n_mask_offline) / len(ak.flatten(gen_b_from_higgs))\n",
    "\n",
    "    true_pt_l1_mask = masks[1][:, :k]\n",
    "    more_than_n_mask_l1 = ak.sum(true_pt_l1_mask, axis=1) >= n\n",
    "    more_than_n_efficiency_l1 = ak.sum(more_than_n_mask_l1) / len(ak.flatten(gen_b_from_higgs))\n",
    "\n",
    "    true_btag_offline_mask = masks[2][:, :k]\n",
    "    more_than_n_b_mask_offline = ak.sum(true_btag_offline_mask, axis=1) >= n\n",
    "    more_than_n_b_efficiency_offline = ak.sum(more_than_n_b_mask_offline) / len(ak.flatten(gen_b_from_higgs))\n",
    "\n",
    "    true_btag_l1_mask = masks[3][:, :k]\n",
    "    more_than_n_b_mask_l1 = ak.sum(true_btag_l1_mask, axis=1) >= n\n",
    "    more_than_n_b_efficiency_l1 = ak.sum(more_than_n_b_mask_l1) / len(ak.flatten(gen_b_from_higgs))\n",
    "\n",
    "    return {\"more_than_n_pt\": (more_than_n_efficiency_offline, more_than_n_efficiency_l1),\n",
    "            \"more_than_n_b\": (more_than_n_b_efficiency_offline, more_than_n_b_efficiency_l1),\n",
    "            \"pt_eff\": (eff_pt_offline, eff_pt_l1),\n",
    "            \"btag_eff\": (eff_btag_offline, eff_btag_l1)\n",
    "           }\n",
    "\n",
    "\n",
    "more_than_n_eff_pt_offline = []\n",
    "more_than_n_eff_pt_l1 = []\n",
    "\n",
    "more_than_n_eff_btag_offline = []\n",
    "more_than_n_eff_btag_l1 = []\n",
    "\n",
    "ordered_and_masks = gen_b_masks(events)\n",
    "gen_b_from_higgs = ordered_and_masks[\"gen_b_from_higgs\"]\n",
    "ordered = ordered_and_masks[\"ordered\"]\n",
    "masks = ordered_and_masks[\"masks\"]\n",
    "\n",
    "n = 4\n",
    "\n",
    "for k in range(20):\n",
    "    out_dict = find_n_jets_rolling(gen_b_from_higgs, ordered, masks, n, k+1)\n",
    "\n",
    "    more_than_n_efficiency_offline, more_than_n_efficiency_l1 = out_dict[\"more_than_n_pt\"]\n",
    "    more_than_n_eff_pt_offline.append(more_than_n_efficiency_offline)\n",
    "    more_than_n_eff_pt_l1.append(more_than_n_efficiency_l1)\n",
    "\n",
    "    more_than_n_efficiency_offline, more_than_n_efficiency_l1 = out_dict[\"more_than_n_b\"]\n",
    "    more_than_n_eff_btag_offline.append(more_than_n_efficiency_offline)\n",
    "    more_than_n_eff_btag_l1.append(more_than_n_efficiency_l1)\n",
    "\n",
    "print(f\"\\nPlotting Top-N Jet Efficiencies for N = {n}...\")\n",
    "plt.figure(figsize=(10, 6))\n",
    "plt.step(range(20), more_than_n_eff_pt_offline, where='mid', label='Offline pT')\n",
    "plt.step(range(20), more_than_n_eff_pt_l1, where='mid', label='L1 pT')\n",
    "plt.xlabel(\"k (Number of Top Jets Considered)\")\n",
    "plt.ylabel(f\"Efficiency of Finding at least {n} b-jets\")\n",
    "plt.title(f\"Efficiency of Finding at least {n} b-jets vs. Top k Jets Considered\")\n",
    "plt.grid(True, linestyle='--', alpha=0.6)\n",
    "plt.legend()\n",
    "plt.show()\n",
    "\n",
    "plt.figure(figsize=(10, 6))\n",
    "plt.step(range(20), more_than_n_eff_btag_offline, where='mid', label='Offline BTag')\n",
    "plt.step(range(20), more_than_n_eff_btag_l1, where='mid', label='L1 BTag')\n",
    "plt.xlabel(\"k (Number of Top Jets Considered)\")\n",
    "plt.ylabel(f\"Efficiency of Finding at least {n} b-jets\")\n",
    "plt.title(f\"Efficiency of Finding at least {n} b-jets vs. Top k Jets Considered\")\n",
    "plt.grid(True, linestyle='--', alpha=0.6)\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5f2ce8d9",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "hep-root",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.14.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
