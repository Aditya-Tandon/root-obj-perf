{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aa966abf",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import uproot\n",
    "import awkward as ak\n",
    "import vector\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import warnings\n",
    "\n",
    "# plotting params\n",
    "plt.rcParams.update({\n",
    "    'figure.figsize': (10, 6),\n",
    "    'axes.grid': True,\n",
    "    'grid.alpha': 0.6,\n",
    "    'grid.linestyle': '--',\n",
    "    'font.size': 14,\n",
    "    \"figure.dpi\": 200,\n",
    "})\n",
    "\n",
    "# Suppress a harmless warning from the vector library with awkward arrays\n",
    "warnings.filterwarnings(\"ignore\", message=\"Passing an awkward array to a ufunc\")\n",
    "\n",
    "# Register the vector library with awkward array\n",
    "ak.behavior.update(vector.backends.awkward.behavior)\n",
    "\n",
    "# --- 1. CONFIGURATION ---\n",
    "# All user-changable settings are here.\n",
    "with open(\"hh-bbbb-obj-config.json\", \"r\") as config_file:\n",
    "    CONFIG = json.load(config_file)\n",
    "\n",
    "# --- 2. DATA LOADING & PREPARATION FUNCTIONS ---\n",
    "from data_loading_helpers import load_and_prepare_data, select_gen_b_quarks_from_higgs\n",
    "def load_and_prepare_data(file_pattern, tree_name, collections_to_load, max_events, CONFIG=None):\n",
    "    \"\"\"\n",
    "    Loads the ROOT file, restructures the flat branches into objects,\n",
    "    and creates 4-vector representations.\n",
    "    \"\"\"\n",
    "    print(f\"Loading data from {file_pattern}...\")\n",
    "    if CONFIG is None:\n",
    "        with open(\"hh-bbbb-obj-config.json\", \"r\") as config_file:\n",
    "            CONFIG = json.load(config_file)\n",
    "\n",
    "    try:\n",
    "        events = uproot.concatenate(\n",
    "                f\"{file_pattern}:{tree_name}\", \n",
    "                library=\"ak\",\n",
    "                entry_stop=max_events \n",
    "            )\n",
    "    except FileNotFoundError:\n",
    "            print(f\"Error: No files found matching '{file_pattern}'. Please update the path.\")\n",
    "            exit()\n",
    "\n",
    "    print(\"Reshaping data into nested objects...\")\n",
    "    for prefix in collections_to_load:\n",
    "        prefixed_fields = [field for field in events.fields if field.startswith(prefix + \"_\")]\n",
    "        if not prefixed_fields:\n",
    "            print(f\"Warning: No fields found with prefix '{prefix}_'. Skipping.\")\n",
    "            continue\n",
    "        field_map = {field.replace(prefix + \"_\", \"\"): events[field] for field in prefixed_fields}\n",
    "        events[prefix] = ak.zip(field_map)\n",
    "\n",
    "    print(\"Creating 4-vector objects...\")\n",
    "    for prefix in collections_to_load:\n",
    "        if prefix in events.fields and \"pt\" in events[prefix].fields:\n",
    "            \n",
    "            # Default to using the raw pt\n",
    "            pt_field = events[prefix].pt\n",
    "\n",
    "            # Handle mass:\n",
    "            if \"mass\" in events[prefix].fields:\n",
    "                mass_field = events[prefix].mass\n",
    "            elif \"et\" in events[prefix].fields:\n",
    "                # Calculate L1 mass from et, pt, and eta\n",
    "                m2 = (events[prefix].et**2 - events[prefix].pt**2) * (np.cosh(events[prefix].eta)**2)\n",
    "                m2_positive = ak.where(m2 < 0, 0, m2)\n",
    "                mass_field = np.sqrt(m2_positive)\n",
    "            else:\n",
    "                mass_field = ak.zeros_like(pt_field)\n",
    "\n",
    "            # Apply pT Corrections if this is the offline jet\n",
    "            if prefix == CONFIG[\"offline\"][\"collection_name\"]:\n",
    "                tagger_name = CONFIG[\"offline\"][\"tagger_name\"]\n",
    "                print(f\"Applying pT regression corrections to {prefix} {tagger_name}...\")\n",
    "                if tagger_name.startswith(\"btagPNet\"):\n",
    "                    pt_corrected = (\n",
    "                        events[prefix].pt \n",
    "                        * events[prefix].PNetRegPtRawCorr \n",
    "                        * events[prefix].PNetRegPtRawCorrNeutrino\n",
    "                    )\n",
    "                elif tagger_name.startswith(\"btagUParTAK4\"):\n",
    "                    pt_corrected = (\n",
    "                        events[prefix].pt \n",
    "                        * events[prefix].UParTAK4RegPtRawCorr \n",
    "                        * events[prefix].UParTAK4RegPtRawCorrNeutrino\n",
    "                    )\n",
    "                else:\n",
    "                    pt_corrected = events[prefix].pt  # No correction if unknown tagger\n",
    "                \n",
    "                pt_corrected = (\n",
    "                    events[prefix].pt \n",
    "                    * events[prefix].PNetRegPtRawCorr \n",
    "                    * events[prefix].PNetRegPtRawCorrNeutrino\n",
    "                )\n",
    "                # Scale mass by the same correction factor\n",
    "                correction_factor = ak.where(events[prefix].pt > 0, pt_corrected / events[prefix].pt, 1.0)\n",
    "                mass_field = mass_field * correction_factor\n",
    "                pt_field = pt_corrected\n",
    "\n",
    "            elif prefix == CONFIG[\"l1\"][\"collection_name\"] and \"ptCorrection\" in events[prefix].fields:\n",
    "                pt_corrected = events[prefix].pt * events[prefix].ptCorrection\n",
    "                correction_factor = ak.where(events[prefix].pt > 0, pt_corrected / events[prefix].pt, 1.0)\n",
    "                mass_field = mass_field * correction_factor\n",
    "                pt_field = pt_corrected\n",
    "\n",
    "            # getting the softmaxed scores for the next gen L1 jets\n",
    "            if prefix == CONFIG[\"l1\"][\"collection_name\"] and CONFIG[\"l1\"][\"collection_name\"].endswith(\"NG\"):\n",
    "                l1_tag_scores = {field: events[prefix][field] for field in events[prefix].fields if field.endswith(\"Score\")}\n",
    "                for score in l1_tag_scores.keys():\n",
    "                    events[prefix, score] = l1_tag_scores[score]\n",
    "\n",
    "                b_v_udscg_score = events[prefix][\"bTagScore\"] / (events[prefix][\"bTagScore\"] + events[prefix][\"cTagScore\"] + events[prefix][\"udsTagScore\"] + events[prefix][\"gTagScore\"])\n",
    "                c_v_b_score = events[prefix][\"cTagScore\"] / (events[prefix][\"cTagScore\"] + events[prefix][\"bTagScore\"])\n",
    "\n",
    "                events[prefix, \"b_v_udscg_score\"] = b_v_udscg_score\n",
    "                events[prefix, \"c_v_b_score\"] = c_v_b_score\n",
    "\n",
    "            events[prefix, \"vector\"] = ak.zip(\n",
    "                { \"pt\": pt_field, \"eta\": events[prefix].eta, \"phi\": events[prefix].phi, \"mass\": mass_field, },\n",
    "                with_name=\"Momentum4D\",\n",
    "            )\n",
    "            et_field = np.sqrt(pt_field**2 + mass_field**2) * np.cosh(events[prefix].eta)\n",
    "            events[prefix, \"et\"] = et_field\n",
    "\n",
    "            e_field = np.sqrt((pt_field * np.cosh(events[prefix].eta))**2 + mass_field**2)\n",
    "            events[prefix, \"e\"] = e_field\n",
    "            \n",
    "    print(f\"Loaded and restructured {len(events)} events.\")\n",
    "    return events\n",
    "\n",
    "def select_gen_b_quarks_from_higgs(events):\n",
    "    \"\"\"\n",
    "    Finds all b-quarks that are direct descendants of a Higgs boson.\n",
    "    \"\"\"\n",
    "    print(\"Selecting gen-level b-quarks...\")\n",
    "    is_higgs = events.GenPart.pdgId == 25\n",
    "    higgs_indices = ak.local_index(events.GenPart)[is_higgs]\n",
    "\n",
    "    is_b = abs(events.GenPart.pdgId) == 5\n",
    "    b_mother_idx = events.GenPart.genPartIdxMother\n",
    "    \n",
    "    b_mother_idx_expanded = b_mother_idx[:, :, None]\n",
    "    higgs_indices_expanded = higgs_indices[:, None, :]\n",
    "    \n",
    "    comparison_b = (b_mother_idx_expanded == higgs_indices_expanded)\n",
    "    has_higgs_mother_b = ak.any(comparison_b, axis=2)\n",
    "    \n",
    "    is_b_from_H = is_b & has_higgs_mother_b\n",
    "    gen_b_quarks_from_H = events.GenPart[is_b_from_H]\n",
    "\n",
    "    print(f\"Found {ak.sum(ak.num(gen_b_quarks_from_H))} b-quarks from Higgs decays.\")\n",
    "    return gen_b_quarks_from_H\n",
    "\n",
    "\n",
    "# --- 3. ANALYSIS FUNCTIONS ---\n",
    "def get_efficiency_mask(gen_particles, reco_objects, CONFIG=None):\n",
    "    \"\"\"Returns a boolean mask for gen_particles, True if matched.\"\"\"\n",
    "\n",
    "    if CONFIG is None:\n",
    "        with open(\"hh-bbbb-obj-config.json\", \"r\") as config_file:\n",
    "            CONFIG = json.load(config_file)\n",
    "    \n",
    "    gen_expanded = gen_particles.vector[:, :, None]\n",
    "    reco_expanded = reco_objects.vector[:, None, :]\n",
    "    delta_r_matrix = gen_expanded.deltaR(reco_expanded)\n",
    "    min_delta_r = ak.min(delta_r_matrix, axis=2)\n",
    "    is_matched = min_delta_r < CONFIG[\"matching_cone_size\"]\n",
    "    return ak.fill_none(is_matched, False)\n",
    "\n",
    "def get_purity_mask(gen_particles, reco_objects, CONFIG=None):\n",
    "    \"\"\"Returns a boolean mask for reco_objects, True if matched.\"\"\"\n",
    "    if CONFIG is None:\n",
    "        with open(\"hh-bbbb-obj-config.json\", \"r\") as config_file:\n",
    "            CONFIG = json.load(config_file)\n",
    "    gen_expanded = gen_particles.vector[:, None, :]\n",
    "    reco_expanded = reco_objects.vector[:, :, None]\n",
    "    delta_r_matrix = reco_expanded.deltaR(gen_expanded)\n",
    "    min_delta_r = ak.min(delta_r_matrix, axis=2)\n",
    "    is_matched = min_delta_r < CONFIG[\"matching_cone_size\"]\n",
    "    return ak.fill_none(is_matched, False)\n",
    "\n",
    "def get_efficiency_mask_hungarian(gen_particles, reco_objects, CONFIG=None):\n",
    "    \"\"\"\n",
    "    Matches using Hungarian Algorithm (1-to-1 uniqueness).\n",
    "    Returns a boolean mask for gen_particles.\n",
    "    \"\"\"\n",
    "    if CONFIG is None:\n",
    "        with open(\"hh-bbbb-obj-config.json\", \"r\") as config_file:\n",
    "            CONFIG = json.load(config_file)\n",
    "\n",
    "    is_matched_list = []\n",
    "    for i in range(len(gen_particles)):\n",
    "        gen_vec = gen_particles[i].vector\n",
    "        reco_vec = reco_objects[i].vector\n",
    "        \n",
    "        if len(gen_vec) == 0 or len(reco_vec) == 0:\n",
    "            is_matched_list.append(np.zeros(len(gen_vec), dtype=bool))\n",
    "            continue\n",
    "            \n",
    "        # Shape: (N_gen, N_reco)\n",
    "        # Note: vector library deltaR expects (N, 1) vs (1, M) broadcasting\n",
    "        matrix = reco_vec[:, None].deltaR(gen_vec[None, :])\n",
    "        \n",
    "        # row_ind are indices in Reco, col_ind are indices in Gen\n",
    "        row_ind, col_ind = linear_sum_assignment(matrix)\n",
    "        \n",
    "        valid_matches = matrix[row_ind, col_ind] < CONFIG[\"matching_cone_size\"]\n",
    "        event_mask = np.zeros(len(gen_vec), dtype=bool)\n",
    "        \n",
    "        # Set True only for gen indices that were assigned AND within cone\n",
    "        event_mask[col_ind[valid_matches]] = True\n",
    "        \n",
    "        is_matched_list.append(event_mask)\n",
    "        \n",
    "    return ak.Array(is_matched_list)\n",
    "\n",
    "def get_purity_mask_hungarian(gen_particles, reco_objects, CONFIG=None):\n",
    "    \"\"\"\n",
    "    Matches using Hungarian Algorithm (1-to-1 uniqueness).\n",
    "    Returns a boolean mask for reco_objects.\n",
    "    \"\"\"\n",
    "    if CONFIG is None:\n",
    "        with open(\"hh-bbbb-obj-config.json\", \"r\") as config_file:\n",
    "            CONFIG = json.load(config_file)\n",
    "\n",
    "    is_matched_list = []\n",
    "    for i in range(len(gen_particles)):\n",
    "        gen_vec = gen_particles[i].vector\n",
    "        reco_vec = reco_objects[i].vector\n",
    "        \n",
    "        if len(gen_vec) == 0 or len(reco_vec) == 0:\n",
    "            is_matched_list.append(np.zeros(len(reco_vec), dtype=bool))\n",
    "            continue\n",
    "            \n",
    "        # Shape: (N_reco, N_gen)\n",
    "        # Note: vector library deltaR expects (N, 1) vs (1, M) broadcasting\n",
    "        matrix = reco_vec[:, None].deltaR(gen_vec[None, :])\n",
    "        \n",
    "        # row_ind are indices in Reco, col_ind are indices in Gen\n",
    "        row_ind, col_ind = linear_sum_assignment(matrix)\n",
    "        \n",
    "        valid_matches = matrix[row_ind, col_ind] < CONFIG[\"matching_cone_size\"]\n",
    "        event_mask = np.zeros(len(reco_vec), dtype=bool)\n",
    "        \n",
    "        # Set True only for reco indices that were assigned AND within cone\n",
    "        event_mask[row_ind[valid_matches]] = True\n",
    "        \n",
    "        is_matched_list.append(event_mask)\n",
    "        \n",
    "    return ak.Array(is_matched_list)\n",
    "\n",
    "def calculate_pur_eff_vs_variable(gen_particles, reco_objects, mask, variable, bins, is_purity_plot=False):\n",
    "    \"\"\"\n",
    "    Calculates purity or efficiency vs. a kinematic variable for given reconstructed objects.\n",
    "    Purity is defined as the fraction of reconstructed objects that are matched to a generated particle.\n",
    "    Efficiency is defined as the fraction of generated particles that are matched to a reconstructed object.\n",
    "    Returns the fraction and the error for each bin. The error is calculated using the Ullrich and Xu method.\n",
    "    \"\"\"\n",
    "\n",
    "    if is_purity_plot:\n",
    "        all_var = ak.to_numpy(ak.flatten(getattr(reco_objects, variable)))\n",
    "        matched_var = ak.to_numpy(ak.flatten(getattr(reco_objects[mask], variable)))\n",
    "    else:\n",
    "        all_var = ak.to_numpy(ak.flatten(getattr(gen_particles, variable)))\n",
    "        matched_var = ak.to_numpy(ak.flatten(getattr(gen_particles[mask], variable)))\n",
    "    \n",
    "    h_total, _ = np.histogram(all_var, bins=bins)\n",
    "    h_matched, _ = np.histogram(matched_var, bins=bins)\n",
    "    \n",
    "    frac_offline = np.divide(h_matched, h_total, out=np.zeros_like(h_total, dtype=float), where=h_total!=0)\n",
    "    err_offline = np.sqrt(((h_matched + 1) * (h_total - h_matched + 1)) / ((h_total + 2)**2 * (h_total + 3)))  # Ullrich and Xu\n",
    "\n",
    "    return frac_offline, err_offline\n",
    "\n",
    "def calculate_roc_points(reco_jets, is_pure_mask, tagger_name):\n",
    "    \"\"\"\n",
    "    Calculates efficiency and mistag points for a ROC curve.\n",
    "    Returns (mistag_points, efficiency_points, auc_score).\n",
    "    \"\"\"\n",
    "    thresholds = np.linspace(min(0, ak.min(getattr(reco_jets, tagger_name))), max(1, ak.max(getattr(reco_jets, tagger_name))), 400)\n",
    "    eff_points, mistag_points = [], []\n",
    "\n",
    "    signal_jets = reco_jets[is_pure_mask]\n",
    "    mistag_jets = reco_jets[~is_pure_mask]\n",
    "\n",
    "    n_total_signal = ak.sum(ak.num(signal_jets))\n",
    "    n_total_mistag = ak.sum(ak.num(mistag_jets))\n",
    "\n",
    "    for cut in thresholds:\n",
    "        # Calculate Signal Efficiency\n",
    "        n_signal_passing = ak.sum(getattr(signal_jets, tagger_name) > cut)\n",
    "        eff = n_signal_passing / n_total_signal if n_total_signal > 0 else 0\n",
    "        \n",
    "        # Calculate Mistag Rate\n",
    "        n_mistag_passing = ak.sum(getattr(mistag_jets, tagger_name) > cut)\n",
    "        mistag_rate = n_mistag_passing / n_total_mistag if n_total_mistag > 0 else 0\n",
    "        \n",
    "        eff_points.append(eff)\n",
    "        mistag_points.append(mistag_rate)\n",
    "\n",
    "    auc_score = auc(mistag_points, eff_points)\n",
    "    return mistag_points, eff_points, auc_score, thresholds\n",
    "\n",
    "\n",
    "# --- 4. PLOTTING FUNCTIONS ---\n",
    "def plot_signal_background_histogram(reco_jets, is_pure_mask, bins, variable, xlabel, title):\n",
    "    \"\"\"\n",
    "    Plots histograms of signal and background vs. a kinematic variable.\n",
    "    \"\"\"\n",
    "    plt.figure(figsize=(10, 6))\n",
    "    \n",
    "    bin_centers = 0.5 * (bins[1:] + bins[:-1])\n",
    "\n",
    "    signal_data = ak.to_numpy(ak.flatten(getattr(reco_jets[is_pure_mask], variable)))\n",
    "    background_data = ak.to_numpy(ak.flatten(getattr(reco_jets[~is_pure_mask], variable)))\n",
    "\n",
    "    h_signal, _ = np.histogram(signal_data, bins=bins)\n",
    "    h_background, _ = np.histogram(background_data, bins=bins)\n",
    "\n",
    "    plt.hist(signal_data, bins=bins, histtype=\"step\", label='Signal', color='blue')\n",
    "    plt.hist(background_data, bins=bins, histtype=\"step\", label='Background', color='red')\n",
    "\n",
    "    plt.xlabel(xlabel)\n",
    "    plt.ylabel(\"Counts\")\n",
    "    plt.title(title)\n",
    "    plt.grid(True, linestyle='--', alpha=0.6)\n",
    "    plt.legend()\n",
    "    plt.show()\n",
    "\n",
    "def plot_kinematic_comparison(bins, variable, xlabel, title,\n",
    "                              gen_particles,\n",
    "                              objects, \n",
    "                              is_purity_plot=False,\n",
    "                              fmt=\"o-\", new_fig=True,\n",
    "                              legend_postfix=\"\"):\n",
    "    \"\"\"\n",
    "    Plots efficiency or purity vs. a kinematic variable for objects input.\n",
    "    Objects is a list of tuples: [(label, object_collection, mask)]\n",
    "    \"\"\"\n",
    "    if new_fig:\n",
    "        plt.figure(figsize=(10, 6))\n",
    "    \n",
    "    bin_centers = 0.5 * (bins[1:] + bins[:-1])\n",
    "\n",
    "    for obj in objects:\n",
    "        obj_label, obj_collection, obj_mask = obj\n",
    "        y_values, y_errors = calculate_pur_eff_vs_variable(\n",
    "            gen_particles, obj_collection, obj_mask, variable, bins, is_purity_plot=is_purity_plot\n",
    "        )\n",
    "        plt.errorbar(\n",
    "            bin_centers, y_values, yerr=y_errors, fmt=fmt, label=f\"{obj_label}{legend_postfix}\"\n",
    "        )\n",
    "    plt.xlabel(xlabel)\n",
    "    plt.ylabel(\"Purity\" if is_purity_plot else \"Efficiency\")\n",
    "    plt.title(title)\n",
    "    plt.grid(True, linestyle='--', alpha=0.6)\n",
    "    plt.ylim(0, 1.05)\n",
    "    plt.legend()\n",
    "    if new_fig:\n",
    "        plt.show()\n",
    "\n",
    "def plot_roc_comparison(roc_results, working_point=None):\n",
    "    \"\"\"\n",
    "    Plots multiple ROC curves on the same axes.\n",
    "    roc_results should be a list of tuples:\n",
    "    [(label, (mistag_points, eff_points, auc_score)), ...]\n",
    "    \"\"\"\n",
    "    plt.figure(figsize=(8, 8))\n",
    "    \n",
    "    for label, (mistag_pts, eff_pts, auc_score, _) in roc_results:\n",
    "        plt.plot( mistag_pts, eff_pts, 'o-', \n",
    "                 label=f'{label} (AUC = {auc_score:.3f})', \n",
    "                 markersize=2)\n",
    "    \n",
    "    if working_point != None:\n",
    "        plt.vlines(working_point, ymin=0, ymax=1, colors=\"black\", linestyles=\"dashed\", label=f\"WP = {working_point*100}% Mistag rate\")\n",
    "\n",
    "    plt.ylabel(\"B-Tagging Efficiency\")\n",
    "    plt.xlabel(\"Mistag Rate\")\n",
    "    plt.xscale('log') \n",
    "    plt.xlim(1e-4, 1.0) \n",
    "    plt.ylim(1e-4, 1.05)\n",
    "    plt.title(\"ROC Curve Comparison: Offline vs. L1 B-Tagging\")\n",
    "    plt.grid(True, linestyle='--', which='both', alpha=0.6)\n",
    "    plt.legend(fontsize=\"small\")\n",
    "    plt.show()\n",
    "\n",
    "def plot_btag_map(jets, tagger_name, pt_bins, eta_bins):\n",
    "    \"\"\"\n",
    "    Plots a 2D heatmap of the average b-tag score vs. eta and jet pT.\n",
    "    \"\"\"\n",
    "    print(f\"Plotting 2D b-tag map for {tagger_name}...\")\n",
    "    \n",
    "    # Flatten the jet properties into simple numpy arrays\n",
    "    jet_pt = ak.to_numpy(ak.flatten(jets.vector.pt))\n",
    "    jet_eta = ak.to_numpy(ak.flatten(jets.vector.eta))\n",
    "    jet_btag = ak.to_numpy(ak.flatten(getattr(jets, tagger_name)))\n",
    "\n",
    "    # --- Create the 2D Profile ---\n",
    "    \n",
    "    # 1. Create a 2D histogram of the SUM of b-tag scores in each bin\n",
    "    #    We use the 'weights' argument to sum the b-tag scores\n",
    "    h_sum_btag, xedges, yedges = np.histogram2d(\n",
    "        jet_eta, jet_pt, bins=[eta_bins, pt_bins], weights=jet_btag\n",
    "    )\n",
    "    \n",
    "    # 2. Create a 2D histogram of the COUNT of jets in each bin\n",
    "    h_count_jets, _, _ = np.histogram2d(\n",
    "        jet_eta, jet_pt, bins=[eta_bins, pt_bins]\n",
    "    )\n",
    "    \n",
    "    # 3. Calculate the average score per bin\n",
    "    #    Use np.divide to safely handle division by zero (for empty bins)\n",
    "    h_avg_btag = np.divide(\n",
    "        h_sum_btag, \n",
    "        h_count_jets, \n",
    "        out=np.zeros_like(h_sum_btag), \n",
    "        where=(h_count_jets != 0)\n",
    "    )\n",
    "\n",
    "    # --- Plotting ---\n",
    "    # Use pcolormesh to plot the 2D array. Transpose (T) is needed\n",
    "    # because numpy histogram and pcolormesh have different axis conventions.\n",
    "    im = plt.pcolormesh(\n",
    "        xedges, \n",
    "        yedges, \n",
    "        h_avg_btag.T, \n",
    "        cmap=\"jet\",         # A common colormap for this\n",
    "        norm=colors.Normalize(vmin=0.0, vmax=1.0) # Keep color scale 0-1\n",
    "    )\n",
    "    \n",
    "    plt.ylabel(r\"Corrected Jet $p_T$ [GeV]\")\n",
    "    plt.xlabel(\"Jet $\\\\eta$\")\n",
    "    plt.title(f\"Average b-tag score ({tagger_name}) vs. $p_T$ and $\\\\eta$\")\n",
    "    \n",
    "    # Add a color bar, which represents your z-axis\n",
    "    cbar = plt.colorbar(im)\n",
    "    cbar.set_label(\"Average b-tag score\")\n",
    "    \n",
    "    plt.show()\n",
    "\n",
    "def plot_cvb_map(jets, tagger_name, pt_bins, eta_bins):\n",
    "    \"\"\"\n",
    "    Plots a 2D heatmap of the average CvB score vs. eta and jet pT.\n",
    "    \"\"\"\n",
    "    print(f\"Plotting 2D b-tag map for {tagger_name}...\")\n",
    "    \n",
    "    # Flatten the jet properties into simple numpy arrays\n",
    "    jet_pt = ak.to_numpy(ak.flatten(jets.vector.pt))\n",
    "    jet_eta = ak.to_numpy(ak.flatten(jets.vector.eta))\n",
    "    jet_cvb_tag = ak.to_numpy(ak.flatten(getattr(jets, tagger_name)))\n",
    "\n",
    "    # --- Create the 2D Profile ---\n",
    "    \n",
    "    # 1. Create a 2D histogram of the SUM of b-tag scores in each bin\n",
    "    #    We use the 'weights' argument to sum the b-tag scores\n",
    "    h_sum_cvb_tag, xedges, yedges = np.histogram2d(\n",
    "        jet_eta, jet_pt, bins=[eta_bins, pt_bins], weights=jet_cvb_tag\n",
    "    )\n",
    "    \n",
    "    # 2. Create a 2D histogram of the COUNT of jets in each bin\n",
    "    h_count_jets, _, _ = np.histogram2d(\n",
    "        jet_eta, jet_pt, bins=[eta_bins, pt_bins]\n",
    "    )\n",
    "    \n",
    "    # 3. Calculate the average score per bin\n",
    "    #    Use np.divide to safely handle division by zero (for empty bins)\n",
    "    h_avg_cvb_tag = np.divide(\n",
    "        h_sum_cvb_tag, \n",
    "        h_count_jets, \n",
    "        out=np.zeros_like(h_sum_cvb_tag), \n",
    "        where=(h_count_jets != 0)\n",
    "    )\n",
    "\n",
    "    # --- Plotting ---\n",
    "    # Use pcolormesh to plot the 2D array. Transpose (T) is needed\n",
    "    # because numpy histogram and pcolormesh have different axis conventions.\n",
    "    im = plt.pcolormesh(\n",
    "        xedges, \n",
    "        yedges, \n",
    "        h_avg_cvb_tag.T, \n",
    "        cmap=\"jet\",         # A common colormap for this\n",
    "        norm=colors.Normalize(vmin=0.0, vmax=1.0) # Keep color scale 0-1\n",
    "    )\n",
    "    \n",
    "    plt.ylabel(r\"Corrected Jet $p_T$ [GeV]\")\n",
    "    plt.xlabel(r\"Jet $\\eta$\")\n",
    "    plt.title(f\"Average CvB score ({tagger_name}) vs. $p_T$ and $\\eta$\")\n",
    "    \n",
    "    # Add a color bar, which represents your z-axis\n",
    "    cbar = plt.colorbar(im)\n",
    "    cbar.set_label(\"Average b-tag score\")\n",
    "    \n",
    "    plt.show()\n",
    "\n",
    "def plot_matching_criteria(gen_particles, reco_objects, CONFIG=None):\n",
    "    \"\"\"\n",
    "    Plots a 2D heatmap of (reco_pT / gen_pT) vs. dR\n",
    "    for the closest reco_object to each gen_particle.\n",
    "    \"\"\"\n",
    "    if CONFIG is None:\n",
    "        with open(\"hh-bbbb-obj-config.json\", \"r\") as config_file:\n",
    "            CONFIG = json.load(config_file)\n",
    "    \n",
    "    print(\"Plotting pT response vs. dR matching criteria...\")\n",
    "    \n",
    "    # 1. Create the all-to-all deltaR matrix\n",
    "    # gen_expanded shape: (events, n_gen, 1)\n",
    "    # reco_expanded shape: (events, 1, n_reco)\n",
    "    gen_expanded = gen_particles.vector[:, :, None]\n",
    "    reco_expanded = reco_objects.vector[:, None, :]\n",
    "    delta_r_matrix = gen_expanded.deltaR(reco_expanded)\n",
    "\n",
    "    # 2. Find the index of the closest reco_object for each gen_particle\n",
    "    #    shape: (events, n_gen)\n",
    "    closest_reco_idx = ak.argmin(delta_r_matrix, axis=2)\n",
    "    \n",
    "    # 3. Get the dR value for this closest match\n",
    "    #    shape: (events, n_gen)\n",
    "    min_delta_r = ak.min(delta_r_matrix, axis=2)\n",
    "\n",
    "    # 4. Get the pT of the gen particles\n",
    "    #    shape: (events, n_gen)\n",
    "    gen_pt = gen_particles.vector.pt\n",
    "    \n",
    "    # 5. Get the pT of all reco jets in each event\n",
    "    #    shape: (events, n_reco)\n",
    "    reco_pt = reco_objects.vector.pt\n",
    "    \n",
    "    # 6. Use the 'closest_reco_idx' to \"pick\" the pT of the matched jet\n",
    "    #    This is the \"fancy indexing\" that matches gen to reco\n",
    "    matched_reco_pt = reco_pt[closest_reco_idx]\n",
    "    \n",
    "    # 7. Calculate the pT ratio (reco / gen)\n",
    "    #    We must use ak.where to prevent division by zero\n",
    "    pt_ratio = ak.where(gen_pt > 0, matched_reco_pt / gen_pt, np.nan)\n",
    "\n",
    "    # 8. Flatten everything into 1D numpy arrays for plotting\n",
    "    flat_delta_r = ak.to_numpy(ak.flatten(min_delta_r))\n",
    "    flat_pt_ratio = ak.to_numpy(ak.flatten(pt_ratio))\n",
    "    \n",
    "    # 9. Remove any invalid 'nan' values\n",
    "    valid_mask = ~np.isnan(flat_pt_ratio)\n",
    "    flat_delta_r = flat_delta_r[valid_mask]\n",
    "    flat_pt_ratio = flat_pt_ratio[valid_mask]\n",
    "\n",
    "    # --- Plotting ---\n",
    "    plt.figure(figsize=(10, 8))\n",
    "    \n",
    "    # We use a 2D histogram (hist2d) to create the heatmap\n",
    "    plt.hist2d(\n",
    "        flat_delta_r, \n",
    "        flat_pt_ratio, \n",
    "        bins=[np.linspace(0, 2, 50), np.linspace(0, 2, 50)], \n",
    "        cmap='viridis', \n",
    "        norm=colors.LogNorm()  # Use a log scale for color to see faint spots\n",
    "    )\n",
    "    \n",
    "    # Draw a red line at dR = 0.4 to show our matching cut\n",
    "    plt.axvline(x=CONFIG[\"matching_cone_size\"], color='red', linestyle='--', label=f'Matching Cut (ΔR={CONFIG[\"matching_cone_size\"]})')\n",
    "    \n",
    "    plt.xlabel(\"ΔR (gen b-quark, closest reco jet)\")\n",
    "    plt.ylabel(r\"p$_T$ Response (reco p$_T$ / gen p$_T$)\")\n",
    "    plt.title(\"p$_T$ Response vs. ΔR for b-quark to Jet Matching\")\n",
    "    plt.legend()\n",
    "    \n",
    "    # Add a color bar\n",
    "    cbar = plt.colorbar()\n",
    "    cbar.set_label(\"Number of Gen b-quarks\")\n",
    "    \n",
    "    plt.show()\n",
    "\n",
    "def plot_attr_vs_var(events, obj_collection, attr, variable, bins_attr, bins_var, xlabel, ylabel, title, mask=None):\n",
    "    \"\"\"\n",
    "    Plots a 2D histogram of a given attribute vs. a variable for objects in a specified collection.\n",
    "    \"\"\"\n",
    "    print(f\"Plotting {attr} vs. {variable} for {obj_collection}...\")\n",
    "\n",
    "    objs = events[obj_collection]\n",
    "    attr_values = getattr(objs, attr)\n",
    "    var_values = getattr(objs, variable)\n",
    "\n",
    "    if mask is not None:\n",
    "        attr_values = attr_values[mask]\n",
    "        var_values = var_values[mask]\n",
    "\n",
    "    attr_values = ak.to_numpy(ak.flatten(attr_values))\n",
    "    var_values = ak.to_numpy(ak.flatten(var_values))\n",
    "\n",
    "    plt.figure(figsize=(10, 8))\n",
    "    plt.hist2d(\n",
    "        var_values,\n",
    "        attr_values,\n",
    "        bins=[bins_var, bins_attr],\n",
    "        cmap='viridis',\n",
    "        norm=colors.LogNorm()\n",
    "    )\n",
    "\n",
    "    plt.xlabel(xlabel)\n",
    "    plt.ylabel(ylabel)\n",
    "    plt.title(title)\n",
    "\n",
    "    cbar = plt.colorbar()\n",
    "    cbar.set_label(\"Counts\")\n",
    "\n",
    "    plt.show()\n",
    "\n",
    "def plot_attr_vs_var_proj(events, obj_collection, attr, variable, bins_attr, bins_var, xlabel, ylabel, title, mask=None):\n",
    "    \"\"\"\n",
    "    Plots the counts for the input collection against the variable on the x-axis adn the attribute on the y-axis.\n",
    "    Accompanied by panels showing the projection of the counts onto each axis.\n",
    "    \"\"\"\n",
    "    \n",
    "    \n",
    "    objs = events[obj_collection]\n",
    "    attr_values = getattr(objs, attr)\n",
    "    var_values = getattr(objs, variable)\n",
    "\n",
    "    if mask is not None:\n",
    "        attr_values = attr_values[mask]\n",
    "        var_values = var_values[mask]\n",
    "\n",
    "    attr_values = ak.to_numpy(ak.flatten(attr_values))\n",
    "    var_values = ak.to_numpy(ak.flatten(var_values))\n",
    "\n",
    "    # --- Plotting ---\n",
    "    plt.figure(figsize=(10, 8))\n",
    "    gs = gridspec.GridSpec(2, 2, height_ratios=[3, 1], hspace=0.05, width_ratios=[3, 1], wspace=0.05)\n",
    "    \n",
    "    # Top Panel: Average B-Tag Score\n",
    "    ax0 = plt.subplot(gs[0, 0])\n",
    "    ax0.hist2d(\n",
    "        var_values, attr_values, \n",
    "        bins=[bins_var, bins_attr], \n",
    "        cmap='viridis',\n",
    "        norm=colors.LogNorm()\n",
    "    )\n",
    "    ax0.set_ylabel(ylabel)\n",
    "    ax0.set_title(title)\n",
    "    ax0.set_xticklabels([]) # Hide x-labels for top plot\n",
    "    ax0.set_yticks(np.linspace(min(bins_attr), max(bins_attr), 11)) # Reduce number of y-ticks for clarity\n",
    "    ax0.set_xticks(np.linspace(min(bins_var), max(bins_var), 11)) # Reduce number of x-ticks for clarity\n",
    "    ax0.grid(True, linestyle='--', alpha=0.6)\n",
    "    \n",
    "    # Bottom Panel: Projection on the x-axis \n",
    "    ax1 = plt.subplot(gs[1, 0])\n",
    "    var_counts, _ = np.histogram(var_values, bins=bins_var)\n",
    "    bin_centres = 0.5 * (bins_var[1:] + bins_var[:-1])\n",
    "    ax1.step(bin_centres, var_counts, label=\"Counts\", color=\"black\")\n",
    "    ax1.set_ylabel(\"Counts\")\n",
    "    ax1.set_xlabel(xlabel)\n",
    "    ax1.set_xticks(np.linspace(min(bins_var), max(bins_var), 11)) \n",
    "    ax1.set_yticks(np.linspace(0, max(var_counts), 3)) \n",
    "    # ax1.set_yscale(\"log\") # Counts often span orders of magnitude\n",
    "    ax1.grid(True, linestyle='--', alpha=0.6)\n",
    "    ax1.set_xlim(min(bins_var), max(bins_var))\n",
    "    ax1.legend(fontsize='small')\n",
    "    \n",
    "    # Side Panel: Projection on the y-axis\n",
    "    ax2 = plt.subplot(gs[0, 1])\n",
    "    attr_counts, _ = np.histogram(attr_values, bins=bins_attr)\n",
    "    bin_centres = 0.5 * (bins_attr[1:] + bins_attr[:-1])\n",
    "    ax2.step(attr_counts, bin_centres, label=\"Counts\", color='black')\n",
    "    ax2.set_xlabel(\"Counts\")\n",
    "    # ax2.set_yscale(\"log\") # Counts often span orders of magnitude\n",
    "    ax2.set_yticklabels([]) # Hide y-labels for side plot\n",
    "    ax2.set_xticks(np.linspace(0, max(attr_counts), 2)) # Reduce number of x-ticks for clarity\n",
    "    ax2.set_yticks(np.linspace(min(bins_attr), max(bins_attr), 11)) # Reduce number of y-ticks for clarity\n",
    "    ax2.legend(fontsize='small')\n",
    "    ax2.grid(True, linestyle='--', alpha=0.6)\n",
    "    ax2.set_ylim(min(bins_attr), max(bins_attr))\n",
    "    cbar = plt.colorbar(ax0.collections[0], ax=ax2, pad=0.15)\n",
    "    cbar.set_label(\"Counts\")\n",
    "    \n",
    "    plt.show()\n",
    "\n",
    "def plot_avg_attr_vs_var(reco_jets, is_signal_mask, attr, variable, bins, xlabel, ylabel, title):\n",
    "    \"\"\"\n",
    "    Plots the average of a given attribute vs. a variable for signal and background jets.\n",
    "    \"\"\"\n",
    "    attr_signal_flattened = ak.to_numpy(ak.flatten(getattr(reco_jets[is_signal_mask], attr)))\n",
    "    variable_signal_flattened = ak.to_numpy(ak.flatten(getattr(reco_jets[is_signal_mask], variable)))\n",
    "    attr_background_flattened = ak.to_numpy(ak.flatten(getattr(reco_jets[~is_signal_mask], attr)))\n",
    "    variable_background_flattened = ak.to_numpy(ak.flatten(getattr(reco_jets[~is_signal_mask], variable)))\n",
    "    avg_signal_attr_per_var_bin = []\n",
    "    std_signal_attr_per_var_bin = []\n",
    "    avg_background_attr_per_var_bin = []\n",
    "    std_background_attr_per_var_bin = []\n",
    "    for i in range(len(bins)-1):\n",
    "        bin_mask_signal = (variable_signal_flattened >= bins[i]) & (variable_signal_flattened < bins[i+1])\n",
    "        bin_mask_background = (variable_background_flattened >= bins[i]) & (variable_background_flattened < bins[i+1])\n",
    "        if np.sum(bin_mask_signal) > 0:\n",
    "            avg_signal_attr_per_var_bin.append(np.mean(attr_signal_flattened[bin_mask_signal]))\n",
    "            std_signal_attr_per_var_bin.append(np.std(attr_signal_flattened[bin_mask_signal]) / np.sqrt(np.sum(bin_mask_signal)))\n",
    "        else:\n",
    "            avg_signal_attr_per_var_bin.append(0)\n",
    "            std_signal_attr_per_var_bin.append(0)\n",
    "        if np.sum(bin_mask_background) > 0:\n",
    "            avg_background_attr_per_var_bin.append(np.mean(attr_background_flattened[bin_mask_background]))\n",
    "            std_background_attr_per_var_bin.append(np.std(attr_background_flattened[bin_mask_background]) / np.sqrt(np.sum(bin_mask_background)))\n",
    "        else:\n",
    "            avg_background_attr_per_var_bin.append(0)\n",
    "            std_background_attr_per_var_bin.append(0)\n",
    "    bin_centers = 0.5 * (bins[:-1] + bins[1:])\n",
    "    plt.errorbar(bin_centers, avg_signal_attr_per_var_bin, yerr=std_signal_attr_per_var_bin, marker='o', label=\"Signal Avg\")\n",
    "    plt.errorbar(bin_centers, avg_background_attr_per_var_bin, yerr=std_background_attr_per_var_bin, marker='o', label=\"Background Avg\")\n",
    "    plt.xlabel(xlabel)\n",
    "    plt.ylabel(ylabel)\n",
    "    plt.title(title)\n",
    "    plt.legend()\n",
    "    plt.show()\n",
    "  \n",
    "def plot_resolution_vs_var(gen_var, resolution_values, bins, y_label, x_label, title):\n",
    "    \"\"\"\n",
    "    Bins the data by Gen pT and calculates the Mean and Width (StdDev) \n",
    "    of the resolution in each bin.\n",
    "    \"\"\"\n",
    "    bin_centers = 0.5 * (bins[1:] + bins[:-1])\n",
    "    \n",
    "    means = []\n",
    "    widths = []\n",
    "    errors = [] # Error on the width calculation\n",
    "    \n",
    "    # Digitize: Find which bin each event belongs to\n",
    "    # indices 1 to len(bins)-1 are valid bins\n",
    "    bin_indices = np.digitize(gen_var, bins)\n",
    "    \n",
    "    for i in range(1, len(bins)):\n",
    "        # Select data for this specific bin\n",
    "        data_in_bin = resolution_values[bin_indices == i]\n",
    "        \n",
    "        if len(data_in_bin) > 10: # Require minimum stats\n",
    "            # Calculate Mean (Bias)\n",
    "            mu = np.mean(data_in_bin)\n",
    "            \n",
    "            # Calculate Width (Resolution)\n",
    "            # Standard Deviation is simple, but IQR/2 is more robust against tails\n",
    "            sigma = np.std(data_in_bin) \n",
    "            \n",
    "            # Error on std dev estimate approx: sigma / sqrt(2N)\n",
    "            err = sigma / np.sqrt(2 * len(data_in_bin))\n",
    "            \n",
    "            means.append(mu)\n",
    "            widths.append(sigma)\n",
    "            errors.append(err)\n",
    "        else:\n",
    "            means.append(np.nan)\n",
    "            widths.append(np.nan)\n",
    "            errors.append(0)\n",
    "\n",
    "    # --- Plotting ---\n",
    "    plt.figure(figsize=(10, 8))\n",
    "    \n",
    "    # Top Panel: Resolution (Width)\n",
    "    plt.subplot(2, 1, 1)\n",
    "    plt.errorbar(bin_centers, widths, yerr=errors, fmt='o-', capsize=5, label='Resolution ($\\sigma$)')\n",
    "    plt.ylabel(f\"{y_label} Resolution\")\n",
    "    plt.title(title)\n",
    "    plt.grid(True, linestyle='--', alpha=0.6)\n",
    "    plt.legend()\n",
    "    \n",
    "    # Bottom Panel: Scale/Bias (Mean)\n",
    "    plt.subplot(2, 1, 2)\n",
    "    plt.errorbar(bin_centers, means, fmt='s--', color='red', capsize=5, label='Scale (Mean)')\n",
    "    plt.axhline(0, color='black', linestyle='-', linewidth=1)\n",
    "    plt.xlabel(x_label)\n",
    "    plt.ylabel(f\"{y_label} Scale (Bias)\")\n",
    "    plt.grid(True, linestyle='--', alpha=0.6)\n",
    "    plt.legend()\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "\n",
    "# --- 5. SELECTION CUT FUNCTIONS ---\n",
    "def apply_custom_cuts(reco_jets, config, key):\n",
    "    \"\"\"\n",
    "    Apply custom cuts to a jet collection.\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    reco_jets : awkward.Array\n",
    "        Jet collection (offline or L1).\n",
    "    config : dict\n",
    "        Global CONFIG dict.\n",
    "    key : str\n",
    "        Either \"offline\" or \"l1\" to select the appropriate config.\n",
    "    \"\"\"\n",
    "    subcfg = config[key]\n",
    "\n",
    "    pt_cut = subcfg[\"pt_cut\"]\n",
    "    eta_cut = subcfg[\"eta_cut\"]\n",
    "    b_tag_cut = subcfg[\"b_tag_cut\"]\n",
    "    tagger_name = subcfg[\"tagger_name\"]\n",
    "\n",
    "    print(f\"\\nApplying custom pT cut of {pt_cut} GeV for {key} jets...\")\n",
    "    pt_mask = reco_jets.pt > pt_cut\n",
    "    eta_mask = abs(reco_jets.eta) < eta_cut\n",
    "    final_mask = pt_mask & eta_mask\n",
    "\n",
    "    print(f\"Applying custom cuts for {tagger_name} ({key})...\")\n",
    "\n",
    "    if key == \"offline\":\n",
    "        charm_veto_cut = subcfg[\"charm_veto_cut\"]\n",
    "        electron_veto_cut = subcfg[\"electron_veto_cut\"]\n",
    "        muon_veto_cut = subcfg[\"muon_veto_cut\"]\n",
    "\n",
    "        if tagger_name.startswith(\"btagPNet\"):\n",
    "            b_jet_mask = (reco_jets.btagPNetB > b_tag_cut)\n",
    "            charm_veto_mask = (reco_jets.btagPNetCvB < charm_veto_cut)\n",
    "            final_mask = final_mask & charm_veto_mask & b_jet_mask\n",
    "\n",
    "        elif tagger_name.startswith(\"btagUParTAK4\"):\n",
    "            b_jet_mask = (reco_jets.btagUParTAK4probb > b_tag_cut)\n",
    "            charm_veto_mask = (reco_jets.btagUParTAK4CvB < charm_veto_cut)\n",
    "            electron_veto_mask = (reco_jets.btagUParTAK4Ele < electron_veto_cut)\n",
    "            muon_veto_mask = (reco_jets.btagUParTAK4Mu < muon_veto_cut)\n",
    "            final_mask = (\n",
    "                final_mask\n",
    "                & charm_veto_mask\n",
    "                & electron_veto_mask\n",
    "                & muon_veto_mask\n",
    "                & b_jet_mask\n",
    "            )\n",
    "\n",
    "    elif key == \"l1\":\n",
    "        # For L1, just apply the tagger cut generically\n",
    "        tag_mask = getattr(reco_jets, tagger_name) > b_tag_cut\n",
    "        final_mask = final_mask & tag_mask\n",
    "\n",
    "    elif key == \"l1ext\":\n",
    "        tag_mask = getattr(reco_jets, tagger_name) > b_tag_cut\n",
    "        final_mask = final_mask & tag_mask\n",
    "\n",
    "    reco_jets = reco_jets[final_mask]\n",
    "    return reco_jets\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1f20fc7f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# for comparing the L1NG to the L1ExtJet, offline collections\n",
    "\n",
    "import copy\n",
    "\n",
    "with open(\"hh-bbbb-obj-config.json\", \"r\") as config_file:\n",
    "    CONFIG = json.load(config_file)\n",
    "\n",
    "pt_bins = np.linspace(0, 500, 201)\n",
    "eta_bins = np.linspace(-3, 3, 201)\n",
    "b_tag_bins = np.linspace(0, 1, 101)\n",
    "\n",
    "events = load_and_prepare_data(\n",
    "    CONFIG[\"file_pattern\"], \n",
    "    CONFIG[\"tree_name\"], \n",
    "    [\n",
    "        \"GenPart\", \n",
    "        CONFIG[\"offline\"][\"collection_name\"], \n",
    "        CONFIG[\"l1\"][\"collection_name\"],\n",
    "        \"L1puppiExtJetSC4\"\n",
    "    ], \n",
    "    CONFIG[\"max_events\"]\n",
    ")\n",
    "\n",
    "upart_CONFIG = copy.deepcopy(CONFIG)\n",
    "upart_CONFIG[\"offline\"][\"tagger_name\"] = \"btagUParTAK4B\"\n",
    "\n",
    "upart_events = load_and_prepare_data(\n",
    "    upart_CONFIG[\"file_pattern\"], \n",
    "    upart_CONFIG[\"tree_name\"], \n",
    "    [\n",
    "        upart_CONFIG[\"offline\"][\"collection_name\"],\n",
    "    ], \n",
    "    upart_CONFIG[\"max_events\"],\n",
    "    CONFIG=upart_CONFIG\n",
    ")\n",
    "\n",
    "upart_CONFIG = copy.deepcopy(CONFIG)\n",
    "upart_CONFIG[\"offline\"][\"tagger_name\"] = \"btagUParTAK4B\"\n",
    "\n",
    "gen_b_quarks = select_gen_b_quarks_from_higgs(events)\n",
    "gen_b_quarks = gen_b_quarks[(gen_b_quarks.pt > CONFIG[\"gen\"][\"pt_cut\"]) & (abs(gen_b_quarks.eta) < CONFIG[\"gen\"][\"eta_cut\"])]\n",
    "\n",
    "reco_jets_offline = apply_custom_cuts(events[CONFIG[\"offline\"][\"collection_name\"]], CONFIG, \"offline\")\n",
    "reco_jets_offline_upart = apply_custom_cuts(upart_events[upart_CONFIG[\"offline\"][\"collection_name\"]], upart_CONFIG, \"offline\")\n",
    "reco_jets_l1ng = apply_custom_cuts(events[CONFIG[\"l1\"][\"collection_name\"]], CONFIG, \"l1\")\n",
    "reco_jets_l1ext = apply_custom_cuts(events[CONFIG[\"l1ext\"][\"collection_name\"]], CONFIG, \"l1ext\")\n",
    "\n",
    "# efficiency masks\n",
    "b_quarks_is_matched_offline = get_efficiency_mask(gen_b_quarks, reco_jets_offline)\n",
    "b_quarks_is_matched_offline_upart = get_efficiency_mask(gen_b_quarks, reco_jets_offline_upart)\n",
    "b_quarks_is_matched_l1ng = get_efficiency_mask(gen_b_quarks, reco_jets_l1ng)\n",
    "b_quarks_is_matched_l1ext = get_efficiency_mask(gen_b_quarks, reco_jets_l1ext)\n",
    "eff_objects = [\n",
    "    (\"Offline\", reco_jets_offline, b_quarks_is_matched_offline),\n",
    "    (\"Offline UParT\", reco_jets_offline_upart, b_quarks_is_matched_offline_upart),\n",
    "    (\"L1NG\", reco_jets_l1ng, b_quarks_is_matched_l1ng),\n",
    "    (\"L1ExtJet\", reco_jets_l1ext, b_quarks_is_matched_l1ext)\n",
    "]\n",
    "\n",
    "# purity masks\n",
    "is_reco_jet_pure_offline = get_purity_mask(gen_b_quarks, reco_jets_offline)\n",
    "is_reco_jet_pure_offline_upart = get_purity_mask(gen_b_quarks, reco_jets_offline_upart)\n",
    "is_reco_jet_pure_l1ng = get_purity_mask(gen_b_quarks, reco_jets_l1ng)\n",
    "is_reco_jet_pure_l1ext = get_purity_mask(gen_b_quarks, reco_jets_l1ext)\n",
    "purity_objects = [\n",
    "    (\"Offline\", reco_jets_offline, is_reco_jet_pure_offline),\n",
    "    (\"Offline UParT\", reco_jets_offline_upart, is_reco_jet_pure_offline_upart),\n",
    "    (\"L1NG\", reco_jets_l1ng, is_reco_jet_pure_l1ng),\n",
    "    (\"L1ExtJet\", reco_jets_l1ext, is_reco_jet_pure_l1ext)\n",
    "]\n",
    "\n",
    "print(\"Plotting reconstruction efficiencies for L1NG vs L1ExtJet...\")\n",
    "plot_kinematic_comparison(\n",
    "    bins=np.linspace(0, 500, 51), variable=\"pt\",\n",
    "    xlabel=r\"Generated b-quark $p_T$ [GeV]\", title=\"Reco Efficiency vs. $p_T$\",\n",
    "    gen_particles=gen_b_quarks,\n",
    "    objects=eff_objects\n",
    ")\n",
    "plot_kinematic_comparison(\n",
    "    bins=np.linspace(-3, 3, 51), variable=\"eta\",\n",
    "    xlabel=\"Generated b-quark $\\\\eta$\", title=\"Reco Efficiency vs. $\\\\eta$\",\n",
    "    gen_particles=gen_b_quarks,\n",
    "    objects=eff_objects\n",
    ")\n",
    "\n",
    "plot_kinematic_comparison(\n",
    "    bins=np.linspace(0, 500, 51), variable=\"pt\",\n",
    "    xlabel=r\"Reconstructed b-quark $p_T$ [GeV]\", title=\"Reco Purity vs. $p_T$\",\n",
    "    gen_particles=gen_b_quarks,\n",
    "    objects=purity_objects,\n",
    "    is_purity_plot=True\n",
    ")\n",
    "plot_kinematic_comparison(\n",
    "    bins=np.linspace(-3, 3, 51), variable=\"eta\",\n",
    "    xlabel=\"Reconstructed b-quark $\\\\eta$\", title=\"Reco Purity vs. $\\\\eta$\",\n",
    "    gen_particles=gen_b_quarks,\n",
    "    objects=purity_objects,\n",
    "    is_purity_plot=True\n",
    ")\n",
    "\n",
    "\n",
    "# plot_btag_map(reco_jets_l1ext, \"btagScore\", pt_bins, eta_bins)\n",
    "# plot_btag_map(reco_jets_offline, CONFIG[\"offline\"][\"tagger_name\"], pt_bins, eta_bins)\n",
    "# plot_btag_map(reco_jets_offline_upart, \"btagUParTAK4B\", pt_bins, eta_bins)\n",
    "# plot_btag_map(reco_jets_l1ng, CONFIG[\"l1\"][\"tagger_name\"], pt_bins, eta_bins)\n",
    "\n",
    "plt.hist(ak.flatten(getattr(reco_jets_l1ext, CONFIG[\"l1ext\"][\"tagger_name\"])), bins=b_tag_bins, histtype=\"step\", label=\"L1ExtJet B-Tag Score\")\n",
    "plt.hist(ak.flatten(getattr(reco_jets_l1ng, CONFIG[\"l1\"][\"tagger_name\"])), bins=b_tag_bins, histtype=\"step\", label=\"L1NG B-Tag Score\")\n",
    "plt.hist(ak.flatten(getattr(reco_jets_offline, CONFIG[\"offline\"][\"tagger_name\"])), bins=b_tag_bins, histtype=\"step\", label=\"Offline B-Tag Score\")\n",
    "plt.hist(ak.flatten(getattr(reco_jets_offline_upart, \"btagUParTAK4B\")), bins=b_tag_bins, histtype=\"step\", label=\"Offline UParT B-Tag Score\")\n",
    "plt.legend()\n",
    "plt.show()\n",
    "\n",
    "# plot_signal_background_histogram(reco_jets_offline, is_reco_jet_pure_offline, pt_bins, \"pt\", r\"Offline Jet $p_T$ [GeV]\", \"Offline Jet $p_T$ Distribution\")\n",
    "# plot_signal_background_histogram(reco_jets_offline_upart, is_reco_jet_pure_offline_upart, pt_bins, \"pt\", r\"Offline UParT Jet $p_T$ [GeV]\", \"Offline UParT Jet $p_T$ Distribution\")\n",
    "# plot_signal_background_histogram(reco_jets_l1ng, is_reco_jet_pure_l1ng, pt_bins, \"pt\", r\"L1NG Jet $p_T$ [GeV]\", \"L1NG Jet $p_T$ Distribution\")\n",
    "# plot_signal_background_histogram(reco_jets_l1ext, is_reco_jet_pure_l1ext, pt_bins, \"pt\", r\"L1ExtJet Jet $p_T$ [GeV]\", \"L1ExtJet Jet $p_T$ Distribution\")\n",
    "\n",
    "# plot_signal_background_histogram(reco_jets_offline, is_reco_jet_pure_offline, np.linspace(-3, 3, 51), \"eta\", \"Offline Jet $\\\\eta$\", \"Offline Jet $\\\\eta$ Distribution\")\n",
    "# plot_signal_background_histogram(reco_jets_offline_upart, is_reco_jet_pure_offline_upart, np.linspace(-3, 3, 51), \"eta\", \"Offline UParT Jet $\\\\eta$\", \"Offline UParT Jet $\\\\eta$ Distribution\")\n",
    "# plot_signal_background_histogram(reco_jets_l1ng, is_reco_jet_pure_l1ng, np.linspace(-3, 3, 51), \"eta\", \"L1NG Jet $\\\\eta$\", \"L1NG Jet $\\\\eta$ Distribution\")\n",
    "# plot_signal_background_histogram(reco_jets_l1ext, is_reco_jet_pure_l1ext, np.linspace(-3, 3, 51), \"eta\", \"L1ExtJet Jet $\\\\eta$\", \"L1ExtJet Jet $\\\\eta$ Distribution\")\n",
    "\n",
    "# plot_signal_background_histogram(reco_jets_offline, is_reco_jet_pure_offline, np.linspace(0, 1, 51), CONFIG[\"offline\"][\"tagger_name\"], \"Offline Jet B-Tag Score\", \"Offline Jet B-Tag Score Distribution\")\n",
    "# plot_signal_background_histogram(reco_jets_offline_upart, is_reco_jet_pure_offline_upart, np.linspace(0, 1, 51), \"btagUParTAK4B\", \"Offline UParT Jet B-Tag Score\", \"Offline UParT Jet B-Tag Score Distribution\")\n",
    "# plot_signal_background_histogram(reco_jets_l1ng, is_reco_jet_pure_l1ng, np.linspace(0, 1, 51), CONFIG[\"l1\"][\"tagger_name\"], \"L1NG Jet B-Tag Score\", \"L1NG Jet B-Tag Score Distribution\")\n",
    "# plot_signal_background_histogram(reco_jets_l1ext, is_reco_jet_pure_l1ext, np.linspace(0, 1, 51), CONFIG[\"l1ext\"][\"tagger_name\"], \"L1ExtJet Jet B-Tag Score\", \"L1ExtJet Jet B-Tag Score Distribution\")\n",
    "\n",
    "offline_roc = calculate_roc_points(\n",
    "    reco_jets_offline, \n",
    "    is_reco_jet_pure_offline, \n",
    "    CONFIG[\"offline\"][\"tagger_name\"]\n",
    ")\n",
    "\n",
    "offline_upart_roc = calculate_roc_points(\n",
    "    reco_jets_offline_upart, \n",
    "    is_reco_jet_pure_offline_upart, \n",
    "    \"btagUParTAK4B\"\n",
    ")\n",
    "\n",
    "l1ng_roc = calculate_roc_points(\n",
    "    reco_jets_l1ng, \n",
    "    is_reco_jet_pure_l1ng, \n",
    "    CONFIG[\"l1\"][\"tagger_name\"]\n",
    ")\n",
    "l1ext_roc = calculate_roc_points(\n",
    "    reco_jets_l1ext, \n",
    "    is_reco_jet_pure_l1ext, \n",
    "    CONFIG[\"l1ext\"][\"tagger_name\"]\n",
    ")\n",
    "\n",
    "plot_roc_comparison([\n",
    "    (f\"Offline {CONFIG[\"offline\"][\"tagger_name\"]}\", offline_roc),\n",
    "    (f\"Offline UParT\", offline_upart_roc),\n",
    "    (\"L1NG\", l1ng_roc),\n",
    "    (\"L1ExtJet\", l1ext_roc)\n",
    "    ],\n",
    "    working_point=0.001\n",
    ")\n",
    "\n",
    "\n",
    "mistag_offline, eff_offline, auc_offline, thresh_offline = offline_roc\n",
    "mistag_offline_upart, eff_offline_upart, auc_offline_upart, thresh_offline_upart = offline_upart_roc\n",
    "mistag_l1, eff_l1, auc_l1, thresh_l1 = l1ng_roc\n",
    "mistag_l1ext, eff_l1ext, auc_l1ext, thresh_l1ext = l1ext_roc\n",
    "\n",
    "def get_roc_point_at_efficiency(mistag, eff, thresh, target_eff):\n",
    "    return [(m, e, th) for m, e, th in zip(mistag, eff, thresh) if e >= target_eff][-1]\n",
    "\n",
    "def get_roc_point_at_mistag(mistag, eff, thresh, target_mistag):\n",
    "    return [(m, e, th) for m, e, th in zip(mistag, eff, thresh) if m >= target_mistag][-1]\n",
    "\n",
    "fpr_offline_tight, tpr_offline_tight, thresh_offline_tight = get_roc_point_at_mistag(mistag_offline, eff_offline, thresh_offline, 0.001)\n",
    "fpr_offline_medium, tpr_offline_medium, thresh_offline_medium = get_roc_point_at_mistag(mistag_offline, eff_offline, thresh_offline, 0.01)\n",
    "fpr_offline_loose, tpr_offline_loose, thresh_offline_loose = get_roc_point_at_mistag(mistag_offline, eff_offline, thresh_offline, 0.1)\n",
    "print(f\"\\nOffline \\nAUC: {auc_offline:.4f}\")\n",
    "print(f\"Tight WP: TPR: {tpr_offline_tight * 100:.4f}%, 1/FPR: {1/fpr_offline_tight:.4f}, Threshold: {thresh_offline_tight:.4f}\")\n",
    "print(f\"Medium WP: TPR: {tpr_offline_medium * 100:.4f}%, 1/FPR: {1/fpr_offline_medium:.4f}, Threshold: {thresh_offline_medium:.4f}\")\n",
    "print(f\"Loose WP: TPR: {tpr_offline_loose * 100:.4f}%, 1/FPR: {1/fpr_offline_loose:.4f}, Threshold: {thresh_offline_loose:.4f}\")\n",
    "\n",
    "fpr_offline_upart_tight, tpr_offline_upart_tight, thresh_offline_upart_tight = get_roc_point_at_mistag(mistag_offline_upart, eff_offline_upart, thresh_offline_upart, 0.001)\n",
    "fpr_offline_upart_medium, tpr_offline_upart_medium, thresh_offline_upart_medium = get_roc_point_at_mistag(mistag_offline_upart, eff_offline_upart, thresh_offline_upart, 0.01)\n",
    "fpr_offline_upart_loose, tpr_offline_upart_loose, thresh_offline_upart_loose = get_roc_point_at_mistag(mistag_offline_upart, eff_offline_upart, thresh_offline_upart, 0.1)\n",
    "print(f\"\\nOffline UParT \\nAUC: {auc_offline_upart:.4f}\")\n",
    "print(f\"Tight WP: TPR: {tpr_offline_upart_tight * 100:.4f}%, 1/FPR: {1/fpr_offline_upart_tight:.4f}, Threshold: {thresh_offline_upart_tight:.4f}\")\n",
    "print(f\"Medium WP: TPR: {tpr_offline_upart_medium * 100:.4f}%, 1/FPR: {1/fpr_offline_upart_medium:.4f}, Threshold: {thresh_offline_upart_medium:.4f}\")\n",
    "print(f\"Loose WP: TPR: {tpr_offline_upart_loose * 100:.4f}%, 1/FPR: {1/fpr_offline_upart_loose:.4f}, Threshold: {thresh_offline_upart_loose:.4f}\")\n",
    "\n",
    "\n",
    "fpr_l1_tight, tpr_l1_tight, thresh_l1_tight = get_roc_point_at_mistag(mistag_l1, eff_l1, thresh_l1, 0.001)\n",
    "fpr_l1_medium, tpr_l1_medium, thresh_l1_medium = get_roc_point_at_mistag(mistag_l1, eff_l1, thresh_l1, 0.01)\n",
    "fpr_l1_loose, tpr_l1_loose, thresh_l1_loose = get_roc_point_at_mistag(mistag_l1, eff_l1, thresh_l1, 0.1)\n",
    "print(f\"\\nL1 \\nAUC: {auc_l1:.4f}\")\n",
    "print(f\"Tight WP: TPR: {tpr_l1_tight * 100:.4f}%, 1/FPR: {1/fpr_l1_tight:.4f}, Threshold: {thresh_l1_tight:.4f}\")\n",
    "print(f\"Medium WP: TPR: {tpr_l1_medium * 100:.4f}%, 1/FPR: {1/fpr_l1_medium:.4f}, Threshold: {thresh_l1_medium:.4f}\")\n",
    "print(f\"Loose WP: TPR: {tpr_l1_loose * 100:.4f}%, 1/FPR: {1/fpr_l1_loose:.4f}, Threshold: {thresh_l1_loose:.4f}\")\n",
    "\n",
    "fpr_l1ext_tight, tpr_l1ext_tight, thresh_l1ext_tight = get_roc_point_at_mistag(mistag_l1ext, eff_l1ext, thresh_l1ext, 0.001)\n",
    "fpr_l1ext_medium, tpr_l1ext_medium, thresh_l1ext_medium = get_roc_point_at_mistag(mistag_l1ext, eff_l1ext, thresh_l1ext, 0.01)\n",
    "fpr_l1ext_loose, tpr_l1ext_loose, thresh_l1ext_loose = get_roc_point_at_mistag(mistag_l1ext, eff_l1ext, thresh_l1ext, 0.1)\n",
    "print(f\"\\nL1ExtJet \\nAUC: {auc_l1ext:.4f}\")\n",
    "print(f\"Tight WP: TPR: {tpr_l1ext_tight * 100:.4f}%, 1/FPR: {1/fpr_l1ext_tight:.4f}, Threshold: {thresh_l1ext_tight:.4f}\")\n",
    "print(f\"Medium WP: TPR: {tpr_l1ext_medium * 100:.4f}%, 1/FPR: {1/fpr_l1ext_medium:.4f}, Threshold: {thresh_l1ext_medium:.4f}\")\n",
    "print(f\"Loose WP: TPR: {tpr_l1ext_loose * 100:.4f}%, 1/FPR: {1/fpr_l1ext_loose:.4f}, Threshold: {thresh_l1ext_loose:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b08d2d21",
   "metadata": {},
   "outputs": [],
   "source": [
    "# enquire about the hwPt plot -> solved\n",
    "# Answer: hwPT: raw pT from FPGAs -> cotinuous values in actual pt after a potentilly non-linear mapping from the raw integer values to a continuous pt space - can be ignored for now.\n",
    "reco_jets_l1 = events[CONFIG[\"l1\"][\"collection_name\"]]\n",
    "plt.hist(ak.flatten(reco_jets_l1.hwPt * reco_jets_l1.ptCorrection), bins=np.linspace(0, 1000, 101), histtype=\"step\", label=\"hwPt\")\n",
    "plt.hist(ak.flatten(reco_jets_l1.pt * reco_jets_l1.ptCorrection), bins=np.linspace(0, 1000, 101), histtype=\"step\", label=\"pt\")\n",
    "plt.legend()\n",
    "plt.show()\n",
    "\n",
    "\n",
    "# plt.hist(ak.flatten(reco_jets_l1.c_v_b_score), bins=np.linspace(0, 1, 101), histtype=\"step\", label=\"CvB Score\")\n",
    "plt.hist(ak.flatten(reco_jets_l1.cTagScore), bins=np.linspace(0, 1, 101), histtype=\"step\", label=\"C Score\")\n",
    "plt.hist(ak.flatten(reco_jets_l1.bTagScore), bins=np.linspace(0, 1, 101), histtype=\"step\", label=\"B Score\")\n",
    "# plt.hist(ak.flatten(reco_jets_l1.b_v_udscg_score), bins=np.linspace(0, 1, 101), histtype=\"step\", label=\"BvUDSCG Score\")\n",
    "plt.hist(ak.flatten(reco_jets_l1.udsTagScore), bins=np.linspace(0, 1, 101), histtype=\"step\", label=\"UDS Score\")\n",
    "# plt.hist(ak.flatten(reco_jets_l1.eTagScore), bins=np.linspace(0, 1, 101), histtype=\"step\", label=\"E Score\")\n",
    "plt.legend()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "63a1ebc6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# to see and plot the horns\n",
    "plot_attr_vs_var_proj(events, CONFIG[\"gen\"][\"collection_name\"], \"pt\", \"eta\", \n",
    "    bins_attr=np.linspace(0, 500, 101), bins_var=np.linspace(-3, 3, 101),\n",
    "    xlabel=\"Jet $\\\\eta$\", ylabel=\"Jet $p_T$ [GeV]\",\n",
    "    title=\"Gen Jet $p_T$ vs. $\\\\eta$\"\n",
    ")\n",
    "plot_attr_vs_var_proj(events, CONFIG[\"offline\"][\"collection_name\"], \"pt\", \"eta\", \n",
    "    bins_attr=np.linspace(0, 500, 201), bins_var=np.linspace(-4, 4, 201),\n",
    "    xlabel=\"Jet $\\\\eta$\", ylabel=\"Jet $p_T$ [GeV]\",\n",
    "    title=\"Offline Jet $p_T$ vs. $\\\\eta$\"\n",
    ")\n",
    "plot_attr_vs_var_proj(events, CONFIG[\"offline\"][\"collection_name\"], \"pt\", \"eta\", \n",
    "    bins_attr=np.linspace(0, 500, 201), bins_var=np.linspace(-4, 4, 201),\n",
    "    xlabel=\"Jet $\\\\eta$\", ylabel=\"Jet $p_T$ [GeV]\",\n",
    "    title=\"Offline Pure Jet $p_T$ vs. $\\\\eta$\",\n",
    "    mask=is_reco_jet_pure_offline\n",
    ")\n",
    "plot_attr_vs_var_proj(events, CONFIG[\"offline\"][\"collection_name\"], \"pt\", \"eta\", \n",
    "    bins_attr=np.linspace(0, 500, 201), bins_var=np.linspace(-4, 4, 201),\n",
    "    xlabel=\"Jet $\\\\eta$\", ylabel=\"Jet $p_T$ [GeV]\",\n",
    "    title=\"Offline Impure Jet $p_T$ vs. $\\\\eta$\",\n",
    "    mask=~is_reco_jet_pure_offline\n",
    ")\n",
    "# plot_attr_vs_var_proj(events, CONFIG[\"l1\"][\"collection_name\"], \"pt\", \"eta\", \n",
    "#     bins_attr=np.linspace(0, 500, 101), bins_var=np.linspace(-3, 3, 101),\n",
    "#     xlabel=\"Jet $\\\\eta$\", ylabel=\"Jet $p_T$ [GeV]\",\n",
    "#     title=\"L1NG Jet $p_T$ vs. $\\\\eta$\"\n",
    "# )\n",
    "# plot_attr_vs_var_proj(events, CONFIG[\"l1ext\"][\"collection_name\"], \"pt\", \"eta\",\n",
    "#     bins_attr=np.linspace(0, 500, 101), bins_var=np.linspace(-3, 3, 101),\n",
    "#     xlabel=\"Jet $\\\\eta$\", ylabel=\"Jet $p_T$ [GeV]\",\n",
    "#     title=\"L1ext Jet $p_T$ vs. $\\\\eta$\"\n",
    "# )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a3261e41",
   "metadata": {},
   "outputs": [],
   "source": [
    "# avg b_tag scores\n",
    "plot_objs_pt = [\n",
    "    (reco_jets_offline, is_reco_jet_pure_offline,\n",
    "    CONFIG[\"offline\"][\"tagger_name\"], \"pt\", np.linspace(0, 500, 51),\n",
    "    \"Jet $p_T$ [GeV]\", \"B-Tag Score\",\n",
    "    \"Offline Jet B-Tag Score vs. $p_T$\"),\n",
    "    (reco_jets_offline_upart, is_reco_jet_pure_offline_upart,\n",
    "    \"btagUParTAK4B\", \"pt\", np.linspace(0, 500, 51),\n",
    "    \"Jet $p_T$ [GeV]\", \"B-Tag Score\",\n",
    "    \"Offline UParT Jet B-Tag Score vs. $p_T$\"),\n",
    "    (reco_jets_l1ng, is_reco_jet_pure_l1ng,\n",
    "    CONFIG[\"l1\"][\"tagger_name\"], \"pt\", np.linspace(0, 500, 51),\n",
    "    \"Jet $p_T$ [GeV]\", \"B-Tag Score\",\n",
    "    \"L1NG Jet B-Tag Score vs. $p_T$\"),\n",
    "    (reco_jets_l1ext, is_reco_jet_pure_l1ext,\n",
    "    CONFIG[\"l1ext\"][\"tagger_name\"], \"pt\", np.linspace(0, 500, 51),\n",
    "    \"Jet $p_T$ [GeV]\", \"B-Tag Score\",\n",
    "    \"L1ExtJet Jet B-Tag Score vs. $p_T$\")\n",
    "]\n",
    "\n",
    "for obj in plot_objs_pt:\n",
    "    plot_avg_attr_vs_var(*obj)\n",
    "\n",
    "\n",
    "plot_objs_eta = [\n",
    "    (reco_jets_offline, is_reco_jet_pure_offline,\n",
    "    CONFIG[\"offline\"][\"tagger_name\"], \"eta\", np.linspace(-3, 3, 51),\n",
    "    \"Jet $\\\\eta$\", \"B-Tag Score\",\n",
    "    \"Offline Jet B-Tag Score vs. $\\\\eta$\"),\n",
    "    (reco_jets_offline_upart, is_reco_jet_pure_offline_upart,\n",
    "    \"btagUParTAK4B\", \"eta\", np.linspace(-3, 3, 51),\n",
    "    \"Jet $\\\\eta$\", \"B-Tag Score\",\n",
    "    \"Offline UParT Jet B-Tag Score vs. $\\\\eta$\"),\n",
    "    (reco_jets_l1ng, is_reco_jet_pure_l1ng,\n",
    "    CONFIG[\"l1\"][\"tagger_name\"], \"eta\", np.linspace(-3, 3, 51),\n",
    "    \"Jet $\\\\eta$\", \"B-Tag Score\",\n",
    "    \"L1NG Jet B-Tag Score vs. $\\\\eta$\"),\n",
    "    (reco_jets_l1ext, is_reco_jet_pure_l1ext,\n",
    "    CONFIG[\"l1ext\"][\"tagger_name\"], \"eta\", np.linspace(-3, 3, 51),\n",
    "    \"Jet $\\\\eta$\", \"B-Tag Score\",\n",
    "    \"L1ExtJet Jet B-Tag Score vs. $\\\\eta$\")\n",
    "]\n",
    "for obj in plot_objs_eta:\n",
    "    plot_avg_attr_vs_var(*obj)\n",
    "\n",
    "\n",
    "# reco_offline_hun_mask = get_purity_mask_hungarian(gen_b_quarks, reco_jets_offline)\n",
    "# plot_kinematic_comparison(\n",
    "#     bins=np.linspace(0, 500, 51), variable=\"pt\",\n",
    "#     xlabel=r\"Generated b-quark $p_T$ [GeV]\", title=\"Reco Purity vs. $p_T$ (Hungarian Matching)\",\n",
    "#     gen_particles=gen_b_quarks,\n",
    "#     objects=[\n",
    "#         (\"Offline Jet (Hungarian Matching)\", reco_jets_offline, reco_offline_hun_mask),\n",
    "#         (\"Offline Jet\", reco_jets_offline, is_reco_jet_pure_offline)\n",
    "#     ],\n",
    "#     is_purity_plot=True\n",
    "# )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "30ffeffc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# all histograms together for offline jets\n",
    "\n",
    "plt.hist(ak.flatten((gen_b_quarks.eta)), bins=np.linspace(-4, 4, 81), histtype=\"step\", label=\"Gen b-quarks\")\n",
    "plt.hist(ak.flatten((reco_jets_offline.eta)), bins=np.linspace(-4, 4, 81), histtype=\"step\", label=\"Reco Offline Jets\")\n",
    "plt.hist(ak.flatten((reco_jets_offline[is_reco_jet_pure_offline].eta)), bins=np.linspace(-4, 4, 81), histtype=\"step\", label=\"Reco signal Offline Jets\")\n",
    "plt.hist(ak.flatten((gen_b_quarks[b_quarks_is_matched_offline].eta)), bins=np.linspace(-4, 4, 81), histtype=\"step\", label=\"Matched Gen Jets\")\n",
    "plt.hist(ak.flatten((gen_b_quarks[~b_quarks_is_matched_offline].eta)), bins=np.linspace(-4, 4, 81), histtype=\"step\", label=\"Unmatched Gen Jets\")\n",
    "# plt.hist(ak.flatten((reco_jets_offline[~is_reco_jet_pure_offline].eta)), bins=np.linspace(-4, 4, 51), histtype=\"step\", label=\"Reco background Offline Jets\")\n",
    "plt.legend()\n",
    "plt.xlabel(\"Eta\")\n",
    "plt.ylabel(\"Counts\")\n",
    "plt.show()\n",
    "\n",
    "plt.hist(ak.flatten((gen_b_quarks.pt)), bins=np.linspace(0, 500, 101), histtype=\"step\", label=\"Gen b-quarks\")\n",
    "plt.hist(ak.flatten((reco_jets_offline.pt)), bins=np.linspace(0, 500, 101), histtype=\"step\", label=\"Reco Offline Jets\")\n",
    "plt.hist(ak.flatten((reco_jets_offline[is_reco_jet_pure_offline].pt)), bins=np.linspace(0, 500, 101), histtype=\"step\", label=\"Reco signal Offline Jets\")\n",
    "plt.hist(ak.flatten((gen_b_quarks[b_quarks_is_matched_offline].pt)), bins=np.linspace(0, 500, 101), histtype=\"step\", label=\"Matched Gen Jets\")\n",
    "plt.hist(ak.flatten((gen_b_quarks[~b_quarks_is_matched_offline].pt)), bins=np.linspace(0, 500, 101), histtype=\"step\", label=\"Unmatched Gen Jets\")\n",
    "plt.legend()\n",
    "plt.xlabel(\"pt\")\n",
    "plt.ylabel(\"Counts\")\n",
    "plt.show()\n",
    "\n",
    "plt.hist(ak.flatten((gen_b_quarks.eta)), bins=np.linspace(-4, 4, 51), histtype=\"step\", label=\"Gen b-quarks\")\n",
    "plt.hist(ak.flatten((reco_jets_offline.eta)), bins=np.linspace(-4, 4, 51), histtype=\"step\", label=\"Reco Offline Jets\")\n",
    "plt.hist(ak.flatten((reco_jets_offline[is_reco_jet_pure_offline].eta)), bins=np.linspace(-4, 4, 51), histtype=\"step\", label=\"Reco signal Offline Jets\")\n",
    "plt.hist(ak.flatten((reco_jets_offline[~is_reco_jet_pure_offline].eta)), bins=np.linspace(-4, 4, 51), histtype=\"step\", label=\"Reco background Offline Jets\")\n",
    "plt.legend()\n",
    "plt.xlabel(\"Eta\")\n",
    "plt.ylabel(\"Counts\")\n",
    "plt.show()\n",
    "\n",
    "plt.hist(ak.flatten((gen_b_quarks.pt)), bins=np.linspace(0, 500, 101), histtype=\"step\", label=\"Gen b-quarks\")\n",
    "plt.hist(ak.flatten((reco_jets_offline.pt)), bins=np.linspace(0, 500, 101), histtype=\"step\", label=\"Reco Offline Jets\")\n",
    "plt.hist(ak.flatten((reco_jets_offline[is_reco_jet_pure_offline].pt)), bins=np.linspace(0, 500, 101), histtype=\"step\", label=\"Reco signal Offline Jets\")\n",
    "plt.hist(ak.flatten((reco_jets_offline[~is_reco_jet_pure_offline].pt)), bins=np.linspace(0, 500, 101), histtype=\"step\", label=\"Reco background Offline Jets\")\n",
    "plt.legend()\n",
    "plt.xlabel(\"Pt\")\n",
    "plt.ylabel(\"Counts\")\n",
    "plt.xlim(150, 400)\n",
    "plt.ylim(0, 2000)\n",
    "plt.show()\n",
    "\n",
    "\n",
    "plt.hist(ak.flatten(reco_jets_offline.PNetRegPtRawRes), bins=np.linspace(-1, 1, 101), histtype=\"step\", label=\"Offline PNetRegPtRawRes\")\n",
    "plt.show()\n",
    "\n",
    "plot_matching_criteria(gen_b_quarks, reco_jets_offline)\n",
    "plot_matching_criteria(gen_b_quarks, reco_jets_offline_upart)\n",
    "plot_matching_criteria(gen_b_quarks, reco_jets_l1ng)\n",
    "plot_matching_criteria(gen_b_quarks, reco_jets_l1ext)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ee4bdf7e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Resolution and Scale Plots\n",
    "# TODO: look at Prijith's work on jet energy scale and resolution\n",
    "def calculate_jet_resolutions(gen_particles, reco_objects, CONFIG=None):\n",
    "    \"\"\"\n",
    "    Calculates pT and Energy resolution using vectorized \n",
    "    Cross-Mutual Nearest Neighbor matching (1-to-1).\n",
    "    \n",
    "    Returns:\n",
    "        gen_pt_flat:  The pT of the matched Gen particles (for the x-axis)\n",
    "        pt_res_flat:  (Reco - Gen) / Gen pT resolution\n",
    "        e_res_flat:   (Reco - Gen) / Gen Energy resolution\n",
    "    \"\"\"\n",
    "    if CONFIG is None:\n",
    "        with open(\"hh-bbbb-obj-config.json\", \"r\") as config_file:\n",
    "            CONFIG = json.load(config_file)\n",
    "            \n",
    "    # 1. Prepare 4-vectors for broadcasting\n",
    "    # gen shape: (events, n_gen, 1)\n",
    "    # reco shape: (events, 1, n_reco)\n",
    "    gen_vec = gen_particles.vector[:, :, None]\n",
    "    reco_vec = reco_objects.vector[:, None, :]\n",
    "    \n",
    "    # 2. Calculate DeltaR Matrix (All-to-All)\n",
    "    delta_r_matrix = gen_vec.deltaR(reco_vec)\n",
    "    \n",
    "    # 3. Find Cross-Mutual Nearest Neighbors (Vectorized 1-to-1)\n",
    "    \n",
    "    # For every Gen particle, find index of closest Reco\n",
    "    # shape: (events, n_gen)\n",
    "    idx_closest_reco_to_gen = ak.argmin(delta_r_matrix, axis=2)\n",
    "    \n",
    "    # For every Reco jet, find index of closest Gen\n",
    "    # shape: (events, n_reco)\n",
    "    idx_closest_gen_to_reco = ak.argmin(delta_r_matrix, axis=1)\n",
    "    \n",
    "    # 4. Check the Cross-Match Condition\n",
    "    # We look at the Gen particles. We ask: \n",
    "    # \"Is the Reco jet closest to ME (Gen) also pointing back at ME?\"\n",
    "    \n",
    "    # Get the index of the Gen particle that the closest Reco jet points to\n",
    "    # We use the advanced indexing: array[indices]\n",
    "    back_check_idx = idx_closest_gen_to_reco[idx_closest_reco_to_gen]\n",
    "    \n",
    "    # Create indices for comparison (0, 1, 2...)\n",
    "    gen_indices = ak.local_index(gen_particles, axis=1)\n",
    "    \n",
    "    # A match is valid if:\n",
    "    # 1. The indices match (Mutual agreement)\n",
    "    # 2. The distance is within the cone size\n",
    "    \n",
    "    # Get the actual dR values for the closest matches\n",
    "    min_dr_values = ak.min(delta_r_matrix, axis=2)\n",
    "    \n",
    "    is_mutual_match = (\n",
    "        (back_check_idx == gen_indices) & \n",
    "        (min_dr_values < CONFIG[\"matching_cone_size\"])\n",
    "    )\n",
    "    \n",
    "    # 5. Extract the Matched Objects\n",
    "    matched_gen = gen_particles[is_mutual_match]\n",
    "    \n",
    "    # We need to pull the specific Reco jets that matched these Gen particles\n",
    "    # idx_closest_reco_to_gen contains the indices of the Reco jets we want\n",
    "    # We apply the boolean mask to the INDICES first\n",
    "    matched_reco_indices = idx_closest_reco_to_gen[is_mutual_match]\n",
    "    \n",
    "    # Now select those jets from the reco collection\n",
    "    matched_reco = reco_objects[matched_reco_indices]\n",
    "    \n",
    "    # 6. Calculate Resolutions\n",
    "    # Formula: (Reco - Gen) / Gen\n",
    "    \n",
    "    # Pt Resolution\n",
    "    pt_res = (matched_reco.vector.pt - matched_gen.vector.pt) / matched_gen.vector.pt\n",
    "    \n",
    "    # Energy Resolution\n",
    "    matched_reco.vector[\"energy\"] = np.sqrt((matched_reco.vector.pt * np.cosh(matched_reco.vector.eta)) ** 2 + (matched_reco.vector.mass) ** 2)\n",
    "    e_res = (matched_reco.vector.energy - matched_gen.vector.energy) / matched_gen.vector.energy\n",
    "    \n",
    "    # Flatten arrays for easy plotting\n",
    "    # We return the Gen Pt as the x-axis variable\n",
    "    return (\n",
    "        ak.to_numpy(ak.flatten(matched_gen.vector.eta)),\n",
    "        ak.to_numpy(ak.flatten(matched_gen.vector.pt)), \n",
    "        ak.to_numpy(ak.flatten(pt_res)),\n",
    "        ak.to_numpy(ak.flatten(e_res))\n",
    "    )\n",
    "\n",
    "def plot_resolution_vs_var(objects):\n",
    "    \"\"\"\n",
    "    Bins the data by Gen pT and calculates the Mean and Width (StdDev) \n",
    "    of the resolution in each bin.\n",
    "    \"\"\"\n",
    "    plt.figure(figsize=(10, 8))\n",
    "    for gen_var, resolution_values, bins, y_label, x_label, title in objects:\n",
    "        bin_centers = 0.5 * (bins[1:] + bins[:-1])\n",
    "        \n",
    "        means = []\n",
    "        widths = []\n",
    "        errors = [] # Error on the width calculation\n",
    "        \n",
    "        # Digitize: Find which bin each event belongs to\n",
    "        # indices 1 to len(bins)-1 are valid bins\n",
    "        bin_indices = np.digitize(gen_var, bins)\n",
    "        \n",
    "        for i in range(1, len(bins)):\n",
    "            # Select data for this specific bin\n",
    "            data_in_bin = resolution_values[bin_indices == i]\n",
    "            \n",
    "            if len(data_in_bin) > 10: # Require minimum stats\n",
    "                # Calculate Mean (Bias)\n",
    "                mu = np.mean(data_in_bin)\n",
    "                \n",
    "                # Calculate Width (Resolution)\n",
    "                # Standard Deviation is simple, but IQR/2 is more robust against tails\n",
    "                sigma = np.std(data_in_bin) \n",
    "                \n",
    "                # Error on std dev estimate approx: sigma / sqrt(2N)\n",
    "                err = sigma / np.sqrt(2 * len(data_in_bin))\n",
    "                \n",
    "                means.append(mu)\n",
    "                widths.append(sigma)\n",
    "                errors.append(err)\n",
    "            else:\n",
    "                means.append(np.nan)\n",
    "                widths.append(np.nan)\n",
    "                errors.append(0)\n",
    "\n",
    "        # --- Plotting ---\n",
    "        # Top Panel: Resolution (Width)\n",
    "        plt.subplot(2, 1, 1)\n",
    "        plt.errorbar(bin_centers, widths, yerr=errors, fmt='o-', capsize=5, label=f'{y_label} Resolution ($\\sigma$)')\n",
    "        plt.ylabel(f\"Resolution\")\n",
    "        plt.title(title)\n",
    "        plt.grid(True, linestyle='--', alpha=0.6)\n",
    "        plt.legend()\n",
    "        \n",
    "        # Bottom Panel: Scale/Bias (Mean)\n",
    "        plt.subplot(2, 1, 2)\n",
    "        plt.errorbar(bin_centers, means, fmt='s--', capsize=5, label=f'{y_label} Scale (Mean)')\n",
    "        plt.axhline(0, color='black', linestyle='-', linewidth=1)\n",
    "        plt.xlabel(x_label)\n",
    "        plt.ylabel(\"Scale (Bias)\")\n",
    "        plt.grid(True, linestyle='--', alpha=0.6)\n",
    "        plt.legend()\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "flat_gen_eta, flat_gen_pt, flat_pt_res, flat_e_res = calculate_jet_resolutions(gen_b_quarks, reco_jets_offline)\n",
    "flat_gen_eta_l1ng, flat_gen_pt_l1ng, flat_pt_res_l1ng, flat_e_res_l1ng = calculate_jet_resolutions(gen_b_quarks, reco_jets_l1ng)\n",
    "flat_gen_eta_l1ext, flat_gen_pt_l1ext, flat_pt_res_l1ext, flat_e_res_l1ext = calculate_jet_resolutions(gen_b_quarks, reco_jets_l1ext)\n",
    "\n",
    "pt_res_objects = [\n",
    "    (flat_gen_pt, flat_pt_res, \n",
    "     np.linspace(0, 500, 51),\n",
    "     \"Offline Jet $p_T$\",\n",
    "     \"Generated $p_T$ [GeV]\",\n",
    "     \"Jet $p_T$ Resolution and Scale vs. Generated $p_T$\"),\n",
    "     (flat_gen_pt_l1ng, flat_pt_res_l1ng, \n",
    "     np.linspace(0, 500, 51),\n",
    "     \"L1NG Jet $p_T$\",\n",
    "     \"Generated $p_T$ [GeV]\",\n",
    "     \"Jet $p_T$ Resolution and Scale vs. Generated $p_T$\"),\n",
    "     (flat_gen_pt_l1ext, flat_pt_res_l1ext, \n",
    "     np.linspace(0, 500, 51),\n",
    "     \"L1Ext Jet $p_T$\",\n",
    "     \"Generated $p_T$ [GeV]\",\n",
    "     \"Jet $p_T$ Resolution and Scale vs. Generated $p_T$\")\n",
    "]\n",
    "plot_resolution_vs_var(\n",
    "    pt_res_objects\n",
    ")\n",
    "\n",
    "eta_res_objects = [\n",
    "    (flat_gen_eta, flat_e_res, \n",
    "     np.linspace(-3, 3, 51),\n",
    "     \"PNet Jet $p_T$\",\n",
    "     \"Generated $\\\\eta$\",\n",
    "     \"Jet $p_T$ Resolution and Scale vs. Generated $\\\\eta$\"),\n",
    "\n",
    "     (flat_gen_eta_l1ng, flat_e_res_l1ng, \n",
    "     np.linspace(-3, 3, 51),\n",
    "     \"L1NG Jet $p_T$\",\n",
    "     \"Generated $\\\\eta$\",\n",
    "     \"Jet $p_T$ Resolution and Scale vs. Generated $\\\\eta$\"),\n",
    "\n",
    "     (flat_gen_eta_l1ext, flat_e_res_l1ext, \n",
    "     np.linspace(-3, 3, 51),\n",
    "     \"L1Ext Jet $p_T$\",\n",
    "     \"Generated $\\\\eta$\",\n",
    "     \"Jet $p_T$ Resolution and Scale vs. Generated $\\\\eta$\")\n",
    "]\n",
    "plot_resolution_vs_var(\n",
    "    eta_res_objects\n",
    ")\n",
    "\n",
    "plot_avg_attr_vs_var(\n",
    "    reco_jets_offline, is_reco_jet_pure_offline,\n",
    "    \"PNetRegPtRawRes\", \"pt\", np.linspace(0, 500, 51),\n",
    "    \"Jet $p_T$ [GeV]\", \"PNetRegPtRawRes\",\n",
    "    \"Offline Jet PNetRegPtRawRes vs. $p_T$\"\n",
    ")\n",
    "plot_avg_attr_vs_var(\n",
    "    reco_jets_offline, is_reco_jet_pure_offline,\n",
    "    \"PNetRegPtRawRes\", \"eta\", np.linspace(-3, 3, 51),\n",
    "    \"Jet $\\\\eta$\", \"PNetRegPtRawRes\",\n",
    "    \"Offline Jet PNetRegPtRawRes vs. $\\\\eta$\"\n",
    ")\n",
    "plot_avg_attr_vs_var(\n",
    "    reco_jets_offline_upart, is_reco_jet_pure_offline,\n",
    "    \"UParTAK4RegPtRawRes\", \"pt\", np.linspace(0, 500, 51),\n",
    "    \"Jet $p_T$ [GeV]\", \"UParTAK4RegPtRawRes\",\n",
    "    \"Offline UParT Jet UParTAK4RegPtRawRes vs. $p_T$\"\n",
    ")\n",
    "plot_avg_attr_vs_var(\n",
    "    reco_jets_offline_upart, is_reco_jet_pure_offline,\n",
    "    \"UParTAK4RegPtRawRes\", \"eta\", np.linspace(-3, 3, 51),\n",
    "    \"Jet $\\\\eta$\", \"UParTAK4RegPtRawRes\",\n",
    "    \"Offline UParT Jet UParTAK4RegPtRawRes vs. $\\\\eta$\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8da7e9c5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Storing hungarian masks to disk to speed up future analysis\n",
    "\n",
    "import copy\n",
    "\n",
    "events = load_and_prepare_data(\n",
    "    CONFIG[\"file_pattern\"], \n",
    "    CONFIG[\"tree_name\"], \n",
    "    [\n",
    "        \"GenPart\", \n",
    "        CONFIG[\"offline\"][\"collection_name\"], \n",
    "        CONFIG[\"l1\"][\"collection_name\"],\n",
    "        \"L1puppiExtJetSC4\"\n",
    "    ], \n",
    "    CONFIG[\"max_events\"]\n",
    ")\n",
    "\n",
    "upart_CONFIG = copy.deepcopy(CONFIG)\n",
    "upart_CONFIG[\"offline\"][\"tagger_name\"] = \"btagUParTAK4B\"\n",
    "\n",
    "upart_events = load_and_prepare_data(\n",
    "    upart_CONFIG[\"file_pattern\"], \n",
    "    upart_CONFIG[\"tree_name\"], \n",
    "    [\n",
    "        upart_CONFIG[\"offline\"][\"collection_name\"],\n",
    "    ], \n",
    "    upart_CONFIG[\"max_events\"],\n",
    "    CONFIG=upart_CONFIG\n",
    ")\n",
    "\n",
    "upart_CONFIG = copy.deepcopy(CONFIG)\n",
    "upart_CONFIG[\"offline\"][\"tagger_name\"] = \"btagUParTAK4B\"\n",
    "\n",
    "gen_b_quarks = select_gen_b_quarks_from_higgs(events)\n",
    "gen_b_quarks = gen_b_quarks[(gen_b_quarks.pt > CONFIG[\"gen\"][\"pt_cut\"]) & (abs(gen_b_quarks.eta) < CONFIG[\"gen\"][\"eta_cut\"])]\n",
    "\n",
    "reco_jets_offline = events[CONFIG[\"offline\"][\"collection_name\"]]\n",
    "reco_jets_l1ng = events[CONFIG[\"l1\"][\"collection_name\"]]\n",
    "reco_jets_l1ext = events[\"L1puppiExtJetSC4\"]\n",
    "reco_jets_offline_upart = upart_events[upart_CONFIG[\"offline\"][\"collection_name\"]]\n",
    "\n",
    "\n",
    "print(\"Generating efficiency masks\")\n",
    "b_quarks_is_matched_offline = get_efficiency_mask_hungarian(gen_b_quarks, reco_jets_offline)\n",
    "b_quarks_is_matched_offline_upart = get_efficiency_mask_hungarian(gen_b_quarks, reco_jets_offline_upart)\n",
    "b_quarks_is_matched_l1ng = get_efficiency_mask_hungarian(gen_b_quarks, reco_jets_l1ng)\n",
    "b_quarks_is_matched_l1ext = get_efficiency_mask_hungarian(gen_b_quarks, reco_jets_l1ext)\n",
    "\n",
    "print(\"Generating purity masks\")\n",
    "is_reco_jet_pure_offline = get_purity_mask_hungarian(gen_b_quarks, reco_jets_offline)\n",
    "is_reco_jet_pure_offline_upart = get_purity_mask_hungarian(gen_b_quarks, reco_jets_offline_upart)\n",
    "is_reco_jet_pure_l1 = get_purity_mask_hungarian(gen_b_quarks, reco_jets_l1ng)\n",
    "is_reco_jet_pure_l1ext = get_purity_mask_hungarian(gen_b_quarks, reco_jets_l1ext)\n",
    "\n",
    "\n",
    "# print(\"Storing masks to disk\")\n",
    "mask_list = [\n",
    "    b_quarks_is_matched_offline,\n",
    "    b_quarks_is_matched_offline_upart,\n",
    "    b_quarks_is_matched_l1ng,\n",
    "    b_quarks_is_matched_l1ext,\n",
    "    is_reco_jet_pure_offline,\n",
    "    is_reco_jet_pure_offline_upart,\n",
    "    is_reco_jet_pure_l1,\n",
    "    is_reco_jet_pure_l1ext\n",
    "]\n",
    "key_list = [\n",
    "    \"b_quarks_is_matched_offline\",\n",
    "    \"b_quarks_is_matched_offline_upart\",\n",
    "    \"b_quarks_is_matched_l1ng\",\n",
    "    \"b_quarks_is_matched_l1ext\",\n",
    "    \"is_reco_jet_pure_offline\",\n",
    "    \"is_reco_jet_pure_offline_upart\",\n",
    "    \"is_reco_jet_pure_l1\",\n",
    "    \"is_reco_jet_pure_l1ext\"\n",
    "]\n",
    "with uproot.recreate(f\"mask_data.root\") as file:\n",
    "    for mask, key in zip(mask_list, key_list):\n",
    "        print(f\"Storing mask with {ak.sum(mask)} true entries out of {len(ak.flatten(mask))} total entries ({ak.sum(mask)/len(ak.flatten(mask))*100:.2f}%)\")\n",
    "        file[key] = mask\n",
    "\n",
    "# Reloading\n",
    "print(\"Reloading masks from disk and verifying integrity\")\n",
    "for mask, key in zip(mask_list, key_list):\n",
    "    with uproot.open(\"mask_data.root\") as file:\n",
    "        # .array() converts it back to an Awkward Array\n",
    "        loaded_mask = file[key].array()\n",
    "    assert ak.all(loaded_mask == mask), f\"Loaded mask {key} does not match the original mask!\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d995e39b",
   "metadata": {},
   "outputs": [],
   "source": [
    "mask, key = mask_list[0], key_list[0]\n",
    "with uproot.open(\"mask_data.root\") as file:\n",
    "    # .array() converts it back to an Awkward Array\n",
    "    loaded_mask = file[key]\n",
    "\n",
    "file[b_quarks_is_matched_offline]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b2431043",
   "metadata": {},
   "outputs": [],
   "source": [
    "reco_mass_offline = reco_jets_offline.et\n",
    "mass_mat_offline = reco_mass_offline[:, :, None] + reco_mass_offline[:, None, :]\n",
    "# mass_mat_offline = mass_mat_offline - 120\n",
    "mass_mat_offline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f65a6079",
   "metadata": {},
   "outputs": [],
   "source": [
    "def gen_b_masks(events):\n",
    "    \"\"\"\n",
    "    For each event, checks if at least n b-jets are found within the top k jets.\n",
    "    Returns a boolean mask per event.\n",
    "    \"\"\"\n",
    "\n",
    "    gen_b_from_higgs = select_gen_b_quarks_from_higgs(events)\n",
    "\n",
    "    pt_cut_gen = CONFIG[\"gen\"][\"pt_cut\"]\n",
    "    eta_cut_gen = CONFIG[\"gen\"][\"eta_cut\"]\n",
    "\n",
    "    gen_b_from_higgs = gen_b_from_higgs[(gen_b_from_higgs.pt > pt_cut_gen) & (abs(gen_b_from_higgs.eta) < eta_cut_gen)]\n",
    "\n",
    "    base_jets_offline = events[CONFIG[\"offline\"][\"collection_name\"]]\n",
    "    base_l1_jets = events[CONFIG[\"l1\"][\"collection_name\"]]\n",
    "\n",
    "    pt_ordered_offline = base_jets_offline[ak.argsort(base_jets_offline.vector.pt, ascending=False)]\n",
    "    pt_ordered_l1 = base_l1_jets[ak.argsort(base_l1_jets.vector.pt, ascending=False)]\n",
    "\n",
    "    b_score_ordered_offline = base_jets_offline[ak.argsort(getattr(base_jets_offline, CONFIG[\"offline\"][\"tagger_name\"]), ascending=False)]\n",
    "    b_score_ordered_l1 = base_l1_jets[ak.argsort(getattr(base_l1_jets, CONFIG[\"l1\"][\"tagger_name\"]), ascending=False)]\n",
    "\n",
    "    true_pt_offline_mask = get_purity_mask(gen_b_from_higgs, pt_ordered_offline)\n",
    "    true_pt_l1_mask = get_purity_mask(gen_b_from_higgs, pt_ordered_l1)\n",
    "\n",
    "    true_btag_offline_mask = get_purity_mask(gen_b_from_higgs, b_score_ordered_offline)\n",
    "    true_btag_l1_mask = get_purity_mask(gen_b_from_higgs, b_score_ordered_l1)\n",
    "\n",
    "    pt_ordered_offline = pt_ordered_offline[true_pt_offline_mask]\n",
    "    pt_ordered_l1 = pt_ordered_l1[true_pt_l1_mask]\n",
    "\n",
    "    b_score_ordered_offline = b_score_ordered_offline[true_btag_offline_mask]\n",
    "    b_score_ordered_l1 = b_score_ordered_l1[true_btag_l1_mask]\n",
    "\n",
    "    return {\"gen_b_from_higgs\": gen_b_from_higgs,\n",
    "            \"ordered\": (pt_ordered_offline, pt_ordered_l1, b_score_ordered_offline, b_score_ordered_l1), \n",
    "            \"masks\": (true_pt_offline_mask, true_pt_l1_mask, true_btag_offline_mask, true_btag_l1_mask)\n",
    "            }\n",
    "\n",
    "def find_n_jets_rolling(gen_b_from_higgs, ordered, masks, n, k):\n",
    "    top_k_pt_offline = ordered[0][:, :k]\n",
    "    top_k_pt_l1 = ordered[1][:, :k]\n",
    "\n",
    "    top_k_btag_offline = ordered[2][:, :k]\n",
    "    top_k_btag_l1 = ordered[3][:, :k]\n",
    "\n",
    "    eff_pt_offline = ak.sum(ak.num(top_k_pt_offline)) / ak.sum(ak.num(gen_b_from_higgs))\n",
    "    eff_pt_l1 = ak.sum(ak.num(top_k_pt_l1)) / ak.sum(ak.num(gen_b_from_higgs))\n",
    "\n",
    "    eff_btag_offline = ak.sum(ak.num(top_k_btag_offline)) / ak.sum(ak.num(gen_b_from_higgs))\n",
    "    eff_btag_l1 = ak.sum(ak.num(top_k_btag_l1)) / ak.sum(ak.num(gen_b_from_higgs))\n",
    "\n",
    "    true_pt_offline_mask = masks[0][:, :k]\n",
    "    more_than_n_mask_offline = ak.sum(true_pt_offline_mask, axis=1) >= n\n",
    "    more_than_n_efficiency_offline = ak.sum(more_than_n_mask_offline) / len(ak.flatten(gen_b_from_higgs))\n",
    "\n",
    "    true_pt_l1_mask = masks[1][:, :k]\n",
    "    more_than_n_mask_l1 = ak.sum(true_pt_l1_mask, axis=1) >= n\n",
    "    more_than_n_efficiency_l1 = ak.sum(more_than_n_mask_l1) / len(ak.flatten(gen_b_from_higgs))\n",
    "\n",
    "    true_btag_offline_mask = masks[2][:, :k]\n",
    "    more_than_n_b_mask_offline = ak.sum(true_btag_offline_mask, axis=1) >= n\n",
    "    more_than_n_b_efficiency_offline = ak.sum(more_than_n_b_mask_offline) / len(ak.flatten(gen_b_from_higgs))\n",
    "\n",
    "    true_btag_l1_mask = masks[3][:, :k]\n",
    "    more_than_n_b_mask_l1 = ak.sum(true_btag_l1_mask, axis=1) >= n\n",
    "    more_than_n_b_efficiency_l1 = ak.sum(more_than_n_b_mask_l1) / len(ak.flatten(gen_b_from_higgs))\n",
    "\n",
    "    return {\"more_than_n_pt\": (more_than_n_efficiency_offline, more_than_n_efficiency_l1),\n",
    "            \"more_than_n_b\": (more_than_n_b_efficiency_offline, more_than_n_b_efficiency_l1),\n",
    "            \"pt_eff\": (eff_pt_offline, eff_pt_l1),\n",
    "            \"btag_eff\": (eff_btag_offline, eff_btag_l1)\n",
    "           }\n",
    "\n",
    "\n",
    "more_than_n_eff_pt_offline = []\n",
    "more_than_n_eff_pt_l1 = []\n",
    "\n",
    "more_than_n_eff_btag_offline = []\n",
    "more_than_n_eff_btag_l1 = []\n",
    "\n",
    "ordered_and_masks = gen_b_masks(events)\n",
    "gen_b_from_higgs = ordered_and_masks[\"gen_b_from_higgs\"]\n",
    "ordered = ordered_and_masks[\"ordered\"]\n",
    "masks = ordered_and_masks[\"masks\"]\n",
    "\n",
    "n = 2\n",
    "\n",
    "for k in range(20):\n",
    "    out_dict = find_n_jets_rolling(gen_b_from_higgs, ordered, masks, n, k+1)\n",
    "\n",
    "    more_than_n_efficiency_offline, more_than_n_efficiency_l1 = out_dict[\"more_than_n_pt\"]\n",
    "    more_than_n_eff_pt_offline.append(more_than_n_efficiency_offline)\n",
    "    more_than_n_eff_pt_l1.append(more_than_n_efficiency_l1)\n",
    "\n",
    "    more_than_n_efficiency_offline, more_than_n_efficiency_l1 = out_dict[\"more_than_n_b\"]\n",
    "    more_than_n_eff_btag_offline.append(more_than_n_efficiency_offline)\n",
    "    more_than_n_eff_btag_l1.append(more_than_n_efficiency_l1)\n",
    "\n",
    "print(f\"\\nPlotting Top-N Jet Efficiencies for N = {n}...\")\n",
    "plt.figure(figsize=(10, 6))\n",
    "plt.step(range(20), more_than_n_eff_pt_offline, where='mid', label='Offline pT')\n",
    "plt.step(range(20), more_than_n_eff_pt_l1, where='mid', label='L1 pT')\n",
    "plt.xlabel(\"k (Number of Top Jets Considered)\")\n",
    "plt.ylabel(f\"Efficiency of Finding at least {n} b-jets\")\n",
    "plt.title(f\"Efficiency of Finding at least {n} b-jets vs. Top k Jets Considered\")\n",
    "plt.grid(True, linestyle='--', alpha=0.6)\n",
    "plt.legend()\n",
    "plt.show()\n",
    "\n",
    "plt.figure(figsize=(10, 6))\n",
    "plt.step(range(20), more_than_n_eff_btag_offline, where='mid', label='Offline BTag')\n",
    "plt.step(range(20), more_than_n_eff_btag_l1, where='mid', label='L1 BTag')\n",
    "plt.xlabel(\"k (Number of Top Jets Considered)\")\n",
    "plt.ylabel(f\"Efficiency of Finding at least {n} b-jets\")\n",
    "plt.title(f\"Efficiency of Finding at least {n} b-jets vs. Top k Jets Considered\")\n",
    "plt.grid(True, linestyle='--', alpha=0.6)\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5f2ce8d9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: fix this optmisation code\n",
    "\n",
    "from scipy.optimize import minimize_scalar\n",
    "import warnings\n",
    "\n",
    "def calculate_efficiency_for_cut(reco_jets, gen_b_quarks, tagger_name, cut_value):\n",
    "    \"\"\"\n",
    "    Calculates the b-tagging efficiency for a given cut on the tagger.\n",
    "    Efficiency = (Number of true b-jets passing the cut) / (Total number of true b-jets)\n",
    "    \"\"\"\n",
    "    # Find which reco jets are actually b-jets\n",
    "    is_pure_mask = get_purity_mask(gen_b_quarks, reco_jets)\n",
    "    true_b_jets = reco_jets[is_pure_mask]\n",
    "    \n",
    "    # Find how many of those true b-jets pass the cut\n",
    "    passing_jets = true_b_jets[getattr(true_b_jets, tagger_name) > cut_value]\n",
    "    \n",
    "    # Calculate efficiency\n",
    "    n_passing = ak.sum(ak.num(passing_jets, axis=0))\n",
    "    n_total = ak.sum(ak.num(true_b_jets, axis=0))\n",
    "    \n",
    "    if n_total == 0:\n",
    "        return 0.0\n",
    "        \n",
    "    return n_passing / n_total\n",
    "\n",
    "def objective_function(cut_value, reco_jets, gen_b_quarks, tagger_name, target_efficiency):\n",
    "    \"\"\"\n",
    "    Objective function for the optimizer.\n",
    "    Calculates the squared difference between the current and target efficiency.\n",
    "    \"\"\"\n",
    "    current_efficiency = calculate_efficiency_for_cut(reco_jets, gen_b_quarks, tagger_name, cut_value)\n",
    "    return (current_efficiency - target_efficiency)**2\n",
    "\n",
    "def find_cut_for_efficiency(reco_jets, gen_b_quarks, tagger_name, target_efficiency):\n",
    "    \"\"\"\n",
    "    Uses scipy.optimize.minimize_scalar to find the b-tag cut value that\n",
    "    results in the target b-tagging efficiency.\n",
    "    \"\"\"\n",
    "    print(f\"Optimizing cut for '{tagger_name}' to achieve {target_efficiency:.1%} efficiency...\")\n",
    "    \n",
    "    # The optimizer needs a function that takes only the variable to be optimized (cut_value)\n",
    "    # We use a lambda function to \"freeze\" the other arguments.\n",
    "    obj_func = lambda cut: objective_function(cut, reco_jets, gen_b_quarks, tagger_name, target_efficiency)\n",
    "    \n",
    "    # We use minimize_scalar to find the minimum of our objective function.\n",
    "    # This is equivalent to finding where the efficiency is closest to our target.\n",
    "    with warnings.catch_warnings():\n",
    "        warnings.simplefilter(\"ignore\", RuntimeWarning)\n",
    "        result = minimize_scalar(\n",
    "            obj_func,\n",
    "            bounds=(0.0, 1.0),  # B-tag scores are between 0 and 1\n",
    "            method='bounded'\n",
    "        )\n",
    "    \n",
    "    optimal_cut = result.x\n",
    "    final_efficiency = calculate_efficiency_for_cut(reco_jets, gen_b_quarks, tagger_name, optimal_cut)\n",
    "    \n",
    "    print(f\"Optimization complete:\")\n",
    "    print(f\"  - Target Efficiency: {target_efficiency:.3f}\")\n",
    "    print(f\"  - Optimal Cut Value: {optimal_cut:.4f}\")\n",
    "    print(f\"  - Resulting Efficiency: {final_efficiency:.3f}\")\n",
    "    print(\"-\" * 30)\n",
    "    \n",
    "    return optimal_cut, final_efficiency\n",
    "\n",
    "# --- Run the Optimization ---\n",
    "\n",
    "# Ensure we have the necessary data loaded\n",
    "if 'events' not in locals():\n",
    "    print(\"Reloading data as 'events' was not found in the environment.\")\n",
    "    with open(\"hh-bbbb-obj-config.json\", \"r\") as config_file:\n",
    "        CONFIG = json.load(config_file)\n",
    "    events = run_analysis(CONFIG)\n",
    "\n",
    "# Select gen b-quarks with fiducial cuts\n",
    "gen_b_quarks_for_opt = select_gen_b_quarks_from_higgs(events)\n",
    "gen_b_quarks_for_opt = gen_b_quarks_for_opt[\n",
    "    (gen_b_quarks_for_opt.pt > CONFIG[\"gen\"][\"pt_cut\"]) & \n",
    "    (abs(gen_b_quarks_for_opt.eta) < CONFIG[\"gen\"][\"eta_cut\"])\n",
    "]\n",
    "\n",
    "# Get the reconstructed jet collections\n",
    "reco_jets_offline_for_opt = events[CONFIG[\"offline\"][\"collection_name\"]]\n",
    "reco_jets_l1_for_opt = events[CONFIG[\"l1\"][\"collection_name\"]]\n",
    "\n",
    "# --- Define Target Efficiencies and Run ---\n",
    "target_eff_offline = 0.70  # e.g., 70%\n",
    "target_eff_l1 = 0.70       # e.g., 50%\n",
    "\n",
    "# Find the optimal cut for the Offline jets\n",
    "optimal_cut_offline, final_eff_offline = find_cut_for_efficiency(\n",
    "    reco_jets_offline_for_opt,\n",
    "    gen_b_quarks_for_opt,\n",
    "    CONFIG[\"offline\"][\"tagger_name\"],\n",
    "    target_eff_offline\n",
    ")\n",
    "\n",
    "# Find the optimal cut for the L1 jets\n",
    "optimal_cut_l1, final_eff_l1 = find_cut_for_efficiency(\n",
    "    reco_jets_l1_for_opt,\n",
    "    gen_b_quarks_for_opt,\n",
    "    CONFIG[\"l1\"][\"tagger_name\"],\n",
    "    target_eff_l1\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "460bb705",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "hep-root",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.14.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
